{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Un benvenuto a Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanessamenta/churn/blob/master/Un_benvenuto_a_Colaboratory_obes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdRyKR44dcNI"
      },
      "source": [
        "## Data science\n",
        "\n",
        "Con Colab puoi sfruttare tutta la potenza delle librerie Python per analizzare e visualizzare i dati. La seguente cella di codice usa <strong>numpy</strong> per generare alcuni dati casuali e usa <strong>matplotlib</strong> per visualizzarli. Per modificare il codice, fai clic sulla cella e inizia a modificare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "C4HZx7Gndbrh",
        "outputId": "657f877a-9da2-436b-d72c-0e5296e0ebc0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "ys = 200 + np.random.randn(100)\n",
        "x = [x for x in range(len(ys))]\n",
        "\n",
        "plt.plot(x, ys, '-')\n",
        "plt.fill_between(x, ys, 195, where=(ys > 195), facecolor='g', alpha=0.6)\n",
        "\n",
        "plt.title(\"Sample Visualization\")\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuvYxzt4onis",
        "outputId": "5b5e3ba1-2aa3-4621-9e87-5d1430b3c9e9",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import io\n",
        "data = pd.read_csv(io.BytesIO(uploaded['data.csv']))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-80bf1671-1354-4cdb-b549-3aea7c75b39e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-80bf1671-1354-4cdb-b549-3aea7c75b39e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data.csv to data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL8trv2s4ZKL"
      },
      "source": [
        "\n",
        "bmi=data.loc[data['Type'] == 3]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_kCnsPUqS6o"
      },
      "source": [
        "Puoi importare i tuoi dati nei blocchi note Colab dal tuo account Google Drive, inclusi i fogli di lavoro, da GitHub e molte altre fonti. Per ulteriori informazioni sull'importazione dei dati e sulle possibilit√† di utilizzo di Colab per la data science, vedi i link di seguito, sotto <a href=\"#working-with-data\">Utilizzo dei dati</a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRmls9CQ5L7E"
      },
      "source": [
        "bmi_obeso= bmi.loc[bmi['Value'] > 30]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Ullk4-5Ovu",
        "outputId": "32d64f32-3971-4ce1-875d-0906a8308297",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(bmi_obeso)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         Unnamed: 0  Utente  Sex  Age  Height        Date  Type  Value\n",
            "3948           3948    8002    1   48     167  2016-07-04     3  31.43\n",
            "3969           3969    8002    1   48     167  2016-07-10     3  30.81\n",
            "3986           3986    8002    1   48     167  2016-07-15     3  30.77\n",
            "4010           4010    8002    1   48     167  2016-07-24     3  30.37\n",
            "5523           5523   11321    1   55     179  2016-12-29     3  42.42\n",
            "...             ...     ...  ...  ...     ...         ...   ...    ...\n",
            "7595664     7595664   10793    1   47     183  2017-01-26     3  32.26\n",
            "7595670     7595670   10793    1   47     183  2017-01-27     3  31.92\n",
            "7595678     7595678   10793    1   47     183  2017-01-29     3  32.00\n",
            "7595690     7595690   10793    1   47     183  2017-02-01     3  32.27\n",
            "7595722     7595722   10793    1   47     183  2017-02-10     3  32.05\n",
            "\n",
            "[102815 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXMGgPFj6NH2"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "def _check_param(values):\n",
        "    \n",
        "    \"\"\"\n",
        "    Check the parameter boundaries passed in dict values.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    list of checked parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    if isinstance(values, (list,tuple,np.ndarray)):\n",
        "        return list(set(values))\n",
        "    elif hasattr(values, 'rvs'):\n",
        "        return values\n",
        "    else:\n",
        "        return [values]\n",
        "\n",
        "\n",
        "def _safeformat_str(str, **kwargs):\n",
        "    \n",
        "    \"\"\"\n",
        "    Safe naming formatting for 'trial' and 'fold' token.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    string filled correctly.\n",
        "    \"\"\"\n",
        "    \n",
        "    class SafeDict(dict):\n",
        "        def __missing__(self, key):\n",
        "            return '{' + key + '}'\n",
        "    \n",
        "    replacements = SafeDict(**kwargs)\n",
        "    \n",
        "    return str.format_map(replacements)\n",
        "\n",
        "\n",
        "def _get_callback_paths(callbacks):\n",
        "    \n",
        "    \"\"\"\n",
        "    Extract the saving paths of Keras callbacks that allow the\n",
        "    possibility to create external files.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    list of extracted paths.\n",
        "    \"\"\"\n",
        "    \n",
        "    paths = []\n",
        "    \n",
        "    if isinstance(callbacks, list):\n",
        "        for c in callbacks:\n",
        "            if hasattr(c, 'filepath'):\n",
        "                paths.append(c.filepath)\n",
        "            elif hasattr(c, 'log_dir'):\n",
        "                paths.append(c.log_dir)\n",
        "            elif hasattr(c, 'filename'):\n",
        "                paths.append(c.filename)\n",
        "            elif hasattr(c, 'path'):\n",
        "                paths.append(c.path)\n",
        "            elif hasattr(c, 'root'):\n",
        "                paths.append(c.root)\n",
        "            else:\n",
        "                paths.append(None)\n",
        "    else:\n",
        "        if hasattr(callbacks, 'filepath'):\n",
        "            paths.append(callbacks.filepath)\n",
        "        elif hasattr(callbacks, 'log_dir'):\n",
        "            paths.append(callbacks.log_dir)\n",
        "        elif hasattr(callbacks, 'filename'):\n",
        "            paths.append(callbacks.filename)\n",
        "        elif hasattr(callbacks, 'path'):\n",
        "            paths.append(callbacks.path)\n",
        "        elif hasattr(callbacks, 'root'):\n",
        "            paths.append(callbacks.root)\n",
        "        else:\n",
        "            paths.append(None)\n",
        "            \n",
        "    return paths\n",
        "\n",
        "\n",
        "def _clear_callbacks(callbacks, paths, trial, fold, start_score):\n",
        "    \n",
        "    \"\"\"\n",
        "    Assign the correct saving path to callbacks (if needed) and\n",
        "    restore the starting score.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    list of callbacks.\n",
        "    \"\"\"\n",
        "    \n",
        "    if not isinstance(callbacks, list):\n",
        "        callbacks = [callbacks]\n",
        "    \n",
        "    for i,c in enumerate(callbacks):\n",
        "        if hasattr(c, 'filepath'):\n",
        "            c.filepath = _safeformat_str(paths[i], \n",
        "                                         trial=trial, fold=fold)\n",
        "        elif hasattr(c, 'log_dir'):\n",
        "            c.log_dir = _safeformat_str(paths[i], \n",
        "                                        trial=trial, fold=fold)\n",
        "        elif hasattr(c, 'filename'):\n",
        "            c.filename = _safeformat_str(paths[i], \n",
        "                                         trial=trial, fold=fold)\n",
        "        elif hasattr(c, 'path'):\n",
        "            c.path = _safeformat_str(paths[i], \n",
        "                                     trial=trial, fold=fold)\n",
        "        elif hasattr(c, 'root'):\n",
        "            c.root = _safeformat_str(paths[i], \n",
        "                                     trial=trial, fold=fold)\n",
        "        if hasattr(c, 'best'):\n",
        "            c.best = start_score\n",
        "\n",
        "    return callbacks\n",
        "\n",
        "\n",
        "def _create_fold(X, ids):\n",
        "    \n",
        "    \"\"\"\n",
        "    Create folds from the data received.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    arrays/list or array/dict of arrays containing fold data.\n",
        "    \"\"\"\n",
        "    \n",
        "    if isinstance(X, list):\n",
        "        return [x[ids] for x in X]\n",
        "    \n",
        "    elif isinstance(X, dict):\n",
        "        return {k:v[ids] for k,v in X.items()}\n",
        "    \n",
        "    else:\n",
        "        return X[ids]\n",
        "    \n",
        "\n",
        "def _check_data(X):\n",
        "    \n",
        "    \"\"\"\n",
        "    Data controls for cross validation.\n",
        "    \"\"\"\n",
        "    \n",
        "    if isinstance(X, list):\n",
        "        for x in X:\n",
        "            if not isinstance(x, np.ndarray):\n",
        "                raise ValueError(\n",
        "                    \"Received data in list format. If you are dealing with \"\n",
        "                    \"multi-input or multi-output model, take care to cast each \"\n",
        "                    \"element of the list to numpy array. In case of single-input or \"\n",
        "                    \"single-output, list are not supported: cast them to numpy array.\")\n",
        "    \n",
        "    elif isinstance(X, dict):\n",
        "        for x in X.values():\n",
        "            if not isinstance(x, np.ndarray):\n",
        "                raise ValueError(\n",
        "                    \"Received data in dict format. Take care to cast each \"\n",
        "                    \"value of the dict to numpy array.\")\n",
        "                \n",
        "    elif isinstance(X, np.ndarray):\n",
        "        pass\n",
        "    \n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Data format not appropriate for Keras CV search. \"\n",
        "            \"Supported types are list, dict or numpy array.\")\n",
        "        \n",
        "        \n",
        "\n",
        "class ParameterSampler(object):\n",
        "\n",
        "    # modified from scikit-learn ParameterSampler\n",
        "    \"\"\"\n",
        "    Generator on parameters sampled from given distributions.\n",
        "    Non-deterministic iterable over random candidate combinations for hyper-\n",
        "    parameter search. If all parameters are presented as a list,\n",
        "    sampling without replacement is performed. If at least one parameter\n",
        "    is given as a distribution, sampling with replacement is used.\n",
        "    It is highly recommended to use continuous distributions for continuous\n",
        "    parameters.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    param_distributions : dict\n",
        "        Dictionary with parameters names (`str`) as keys and distributions\n",
        "        or lists of parameters to try. Distributions must provide a ``rvs``\n",
        "        method for sampling (such as those from scipy.stats.distributions).\n",
        "        If a list is given, it is sampled uniformly.\n",
        "        If a list of dicts is given, first a dict is sampled uniformly, and\n",
        "        then a parameter is sampled using that dict as above.\n",
        "    n_iter : integer\n",
        "        Number of parameter settings that are produced.\n",
        "    random_state : int, default None\n",
        "        Pass an int for reproducible output across multiple\n",
        "        function calls.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    param_combi : list of tuple\n",
        "        list of sampled parameter combination\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, param_distributions, n_iter, random_state=None):\n",
        "        \n",
        "        self.n_iter = n_iter\n",
        "        self.random_state = random_state\n",
        "        self.param_distributions = param_distributions\n",
        "\n",
        "    def __init__(self, param_distributions, n_iter, random_state=None):\n",
        "        \n",
        "        self.n_iter = n_iter\n",
        "        self.random_state = random_state\n",
        "        self.param_distributions = param_distributions\n",
        "\n",
        "    def sample(self):\n",
        "        \n",
        "        self.param_distributions = self.param_distributions.copy()\n",
        "        \n",
        "        for p_k, p_v in self.param_distributions.items():\n",
        "            self.param_distributions[p_k] = _check_param(p_v)\n",
        "         \n",
        "        all_lists = all(not hasattr(p, \"rvs\") \n",
        "                        for p in self.param_distributions.values())\n",
        "            \n",
        "        seed = (random.randint(1, 100) if self.random_state is None \n",
        "                else self.random_state+1)\n",
        "        random.seed(seed)\n",
        "        \n",
        "        if all_lists:\n",
        "            param_combi = list(product(*self.param_distributions.values()))\n",
        "            grid_size = len(param_combi)\n",
        "\n",
        "            if grid_size < self.n_iter:\n",
        "                raise ValueError(\n",
        "                    f\"The total space of parameters {grid_size} is smaller \"\n",
        "                    f\"than n_iter={self.n_iter}. Try with KerasGridSearch.\")\n",
        "            param_combi = random.sample(param_combi, self.n_iter)\n",
        "\n",
        "        else:\n",
        "            param_combi = []\n",
        "            k = self.n_iter\n",
        "            for i in range(self.n_iter):\n",
        "                dist = self.param_distributions\n",
        "                params = []\n",
        "                for j,v in enumerate(dist.values()):\n",
        "                    if hasattr(v, \"rvs\"):\n",
        "                        params.append(v.rvs(random_state=seed*(k+j)))\n",
        "                    else:\n",
        "                        params.append(v[random.randint(0,len(v)-1)])\n",
        "                    k += i+j\n",
        "                param_combi.append(tuple(params))\n",
        "        \n",
        "        # reset seed\n",
        "        np.random.mtrand._rand\n",
        "                \n",
        "        return param_combi"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTnscVTa636B"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "class KerasGridSearch(object):\n",
        "    \n",
        "    \"\"\"\n",
        "    Grid hyperparamater searching and optimization on a fixed validation set.\n",
        "    \n",
        "    Pass a Keras model (in Sequential or Functional format), and \n",
        "    a dictionary with the parameter boundaries for the experiment.\n",
        "    For searching, takes in the same arguments available in Keras model.fit(...).\n",
        "    All the input format supported by Keras model are accepted.\n",
        "    \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    hypermodel : function\n",
        "        A callable that takes parameters in dict format and returns a TF Model instance.\n",
        "    param_grid : dict\n",
        "        Hyperparameters to try, 1-to-1 mapped with the parameters dict keys present \n",
        "        in the hypermodel function.\n",
        "    monitor : str, default val_loss\n",
        "        Quantity to monitor in order to detect the best model.\n",
        "    greater_is_better : bool, default False\n",
        "        Whether the quantity to monitor is a score function, meaning high is good, \n",
        "        or a loss function (as default), meaning low is good.\n",
        "    store_model : bool, default True\n",
        "        If True the best model is stored inside the KerasGridSearch object.\n",
        "    savepath : str, default None\n",
        "        String or path-like, path to save the best model file. If None, no saving is applied.\n",
        "    tuner_verbose : int, default 1\n",
        "        0 or 1. Verbosity mode. 0 = silent, 1 = print trial logs with the connected score.\n",
        "        \n",
        "        \n",
        "    Attributes\n",
        "    ----------\n",
        "    trials : list\n",
        "        A list of dicts. The dicts are all the hyperparameter combinations tried and \n",
        "        derived from the param_grid \n",
        "    scores : list \n",
        "        The monitor quantities achived on the validation data by all the models tried.\n",
        "    best_params : dict, default None\n",
        "        The dict containing the best combination (in term of score) of hyperparameters.\n",
        "    best_score : float, default None\n",
        "        The best score achieved by all the possible combination created.\n",
        "    best_model : TF Model, default None\n",
        "        The best model (in term of score). Accessible only if store_model is set to True. \n",
        "        \n",
        "    \n",
        "    Notes\n",
        "    ----------\n",
        "    KerasGridSearch allows the usage of every callbacks available in Keras (also the \n",
        "    custom one). The callbacks, that provide the possibility to save any output as\n",
        "    external files, support naming formatting options. This is true for ModelCheckpoint,\n",
        "    CSVLogger, TensorBoard and RemoteMonitor. 'trial' is the custom token that can be used\n",
        "    to personalize the name formatting. \n",
        "    \n",
        "    For example: if filepath in ModelCheckpoint is model_{trial}.hdf5, then the model \n",
        "    checkpoints will be saved with the relative number of trial in the filename.\n",
        "    This enables to save and differentiate each model created in the searching trials. \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 hypermodel,\n",
        "                 param_grid,\n",
        "                 monitor='val_loss',\n",
        "                 greater_is_better=False,\n",
        "                 store_model=True,\n",
        "                 savepath=None,\n",
        "                 tuner_verbose=1):\n",
        "        \n",
        "        self.hypermodel = hypermodel\n",
        "        self.param_grid = param_grid\n",
        "        self.monitor = monitor\n",
        "        self.greater_is_better = greater_is_better\n",
        "        self.store_model = store_model\n",
        "        self.savepath = savepath\n",
        "        self.tuner_verbose = tuner_verbose\n",
        "        self.trials = []\n",
        "        self.scores = []\n",
        "        self.best_params = None\n",
        "        self.best_score = None\n",
        "        self.best_model = None\n",
        "        \n",
        "        \n",
        "    def set_seed(self,\n",
        "                 seed_fun,\n",
        "                 **seedargs):\n",
        "        \n",
        "        \"\"\"\n",
        "        Pass a function to set the seed in every trial: optional.\n",
        "        \n",
        "        Parameters\n",
        "        ---------- \n",
        "        seed_fun : callable, default None\n",
        "            Function used to set the seed in each trial.\n",
        "        seedargs : Additional arguments of seed_fun.\n",
        "            \n",
        "        Examples\n",
        "        --------\n",
        "        >>> def seed_setter(seed):\n",
        "        >>>     tf.random.set_seed(seed)\n",
        "        >>>     os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "        >>>     np.random.seed(seed)\n",
        "        >>>     random.seed(seed)\n",
        "        >>>\n",
        "        >>> kgs = KerasGridSearch(...)\n",
        "        >>> kgs.set_seed(seed_setter, seed=1234)\n",
        "        >>> kgs.search(...)\n",
        "        \"\"\"\n",
        "        \n",
        "        if not callable(seed_fun):\n",
        "            raise ValueError(\"seed_fun must be a callable function\")\n",
        "        \n",
        "        self.seed_fun = seed_fun\n",
        "        self.seedargs = seedargs\n",
        "        \n",
        "    \n",
        "    def search(self, \n",
        "               x, \n",
        "               y = None, \n",
        "               validation_data = None, \n",
        "               validation_split = 0.0, \n",
        "               **fitargs):\n",
        "        \n",
        "        \"\"\"\n",
        "        Performs a search for best hyperparameter configurations creating\n",
        "        all the possible trials and evaluating on the validation set provided.\n",
        "        \n",
        "        Parameters\n",
        "        ----------       \n",
        "        x : multi types\n",
        "            Input data. All the input format supported by Keras model are accepted.\n",
        "        y : multi types, default None\n",
        "            Target data. All the target format supported by Keras model are accepted.\n",
        "        validation_data : multi types, default None\n",
        "            Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
        "            All the validation_data format supported by Keras model are accepted.\n",
        "        validation_split : float, default 0.0\n",
        "            Float between 0 and 1. Fraction of the training data to be used as validation data.\n",
        "        **fitargs : Additional fitting arguments, the same accepted in Keras model.fit(...).\n",
        "        \"\"\"\n",
        "        \n",
        "        # retrive utility params from CV process (if applied)\n",
        "        fold = self._fold if hasattr(self, '_fold') else ''\n",
        "        callback_paths = (self._callback_paths if hasattr(self, '_callback_paths') \n",
        "                          else '')\n",
        "        \n",
        "        if validation_data is None and validation_split == 0.0:\n",
        "            raise ValueError(\"Pass at least one of validation_data or validation_split\")\n",
        "            \n",
        "        if not isinstance(self.param_grid, dict):\n",
        "            raise ValueError(\"Pass param_grid in dict format\")\n",
        "        self.param_grid = self.param_grid.copy()\n",
        "        \n",
        "        tunable_fitargs = ['batch_size', 'epochs', 'steps_per_epoch', 'class_weight']\n",
        "            \n",
        "        if 'callbacks' in fitargs.keys() and fold == '':\n",
        "            callback_paths = _get_callback_paths(fitargs['callbacks'])\n",
        "            \n",
        "        for p_k, p_v in self.param_grid.items():\n",
        "            self.param_grid[p_k] = _check_param(p_v)\n",
        "        \n",
        "        start_score = -np.inf if self.greater_is_better else np.inf\n",
        "        self.best_score = start_score \n",
        "\n",
        "        eval_epoch = np.argmax if self.greater_is_better else np.argmin\n",
        "        eval_score = np.max if self.greater_is_better else np.min\n",
        "        \n",
        "        total_trials = np.prod([len(p) for p in self.param_grid.values()])\n",
        "        verbose = fitargs['verbose'] if 'verbose' in fitargs.keys() else 0\n",
        "        \n",
        "        if self.tuner_verbose == 1:\n",
        "            print(f\"\\n{total_trials} trials detected for {tuple(self.param_grid.keys())}\")\n",
        "                \n",
        "        for trial,param in enumerate(product(*self.param_grid.values())):\n",
        "            \n",
        "            if hasattr(self, 'seed_fun'):\n",
        "                self.seed_fun(**self.seedargs)\n",
        "                \n",
        "            if 'callbacks' in fitargs.keys():\n",
        "                fitargs['callbacks'] = _clear_callbacks(fitargs['callbacks'], \n",
        "                                                        callback_paths,\n",
        "                                                        trial+1, fold,\n",
        "                                                        start_score)\n",
        "            \n",
        "            param = dict(zip(self.param_grid.keys(), param))\n",
        "            model = self.hypermodel(param)\n",
        "            \n",
        "            fit_param = {k:v for k,v in param.items() if k in tunable_fitargs} \n",
        "            all_fitargs = dict(list(fitargs.items()) + list(fit_param.items()))\n",
        "            \n",
        "            if self.tuner_verbose == 1:\n",
        "                print(f\"\\n***** ({trial+1}/{total_trials}) *****\\nSearch({param})\")\n",
        "            else:\n",
        "                verbose = 0\n",
        "            all_fitargs['verbose'] = verbose\n",
        "                        \n",
        "            model.fit(x = x, \n",
        "                      y = y, \n",
        "                      validation_split = validation_split, \n",
        "                      validation_data = validation_data,\n",
        "                      **all_fitargs)\n",
        "                                    \n",
        "            epoch = eval_epoch(model.history.history[self.monitor])\n",
        "            param['epochs'] = epoch+1\n",
        "            param['steps_per_epoch'] = model.history.params['steps']\n",
        "            param['batch_size'] = (all_fitargs['batch_size'] if 'batch_size' \n",
        "                                   in all_fitargs.keys() else None)\n",
        "            score = np.round(model.history.history[self.monitor][epoch],5)\n",
        "            evaluate = eval_score([self.best_score, score])\n",
        "                    \n",
        "            if self.best_score != evaluate:\n",
        "\n",
        "                self.best_params = param\n",
        "\n",
        "                if self.store_model:\n",
        "                    self.best_model = model\n",
        "\n",
        "                if self.savepath is not None:\n",
        "                    model.save(self.savepath.format(fold=fold))\n",
        "            \n",
        "            self.best_score = evaluate\n",
        "            self.trials.append(param)\n",
        "            self.scores.append(score)\n",
        "            \n",
        "            if self.tuner_verbose == 1:\n",
        "                print(f\"SCORE: {score} at epoch {epoch+1}\")\n",
        "\n",
        "\n",
        "\n",
        "class KerasRandomSearch(object):\n",
        "    \n",
        "    \"\"\"\n",
        "    Random hyperparamater searching and optimization on a fixed validation set.\n",
        "    \n",
        "    Pass a Keras model (in Sequential or Functional format), and \n",
        "    a dictionary with the parameter boundaries for the experiment.\n",
        "    \n",
        "    In contrast to grid-search, not all parameter values are tried out, \n",
        "    but rather a fixed number of parameter settings is sampled from \n",
        "    the specified distributions. The number of parameter settings that \n",
        "    are tried is given by n_iter.\n",
        "    If all parameters are presented as a list, sampling without replacement \n",
        "    is performed. If at least one parameter is given as a distribution \n",
        "    (random variable from scipy.stats.distribution), sampling with replacement \n",
        "    is used. It is highly recommended to use continuous distributions \n",
        "    for continuous parameters.\n",
        "    For searching, takes in the same arguments available in Keras model.fit(...).\n",
        "    All the input format supported by Keras model are accepted.\n",
        "    \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    hypermodel : function\n",
        "        A callable that takes parameters in dict format and returns a TF Model instance.\n",
        "    param_grid : dict\n",
        "        Hyperparameters to try, 1-to-1 mapped with the parameters dict keys present \n",
        "        in the hypermodel function.\n",
        "    n_iter : int\n",
        "        Number of parameter settings that are sampled. \n",
        "        n_iter trades off runtime vs quality of the solution.\n",
        "    sampling_seed : int, default 0\n",
        "        The seed used to sample from the hyperparameter distributions.\n",
        "    monitor : str, default val_loss\n",
        "        Quantity to monitor in order to detect the best model.\n",
        "    greater_is_better : bool, default False\n",
        "        Whether the quantity to monitor is a score function, meaning high is good, \n",
        "        or a loss function (as default), meaning low is good.\n",
        "    store_model : bool, default True\n",
        "        If True the best model is stored inside the KerasRandomSearch object.\n",
        "    savepath : str, default None\n",
        "        String or path-like, path to save the best model file. If None, no saving is applied.\n",
        "    tuner_verbose : int, default 1\n",
        "        0 or 1. Verbosity mode. 0 = silent, 1 = print trial logs with the connected score.\n",
        "        \n",
        "        \n",
        "    Attributes\n",
        "    ----------\n",
        "    trials : list\n",
        "        A list of dicts. The dicts are all the hyperparameter combinations tried and \n",
        "        derived from the param_grid \n",
        "    scores : list \n",
        "        The monitor quantities achived on the validation data by all the models tried.\n",
        "    best_params : dict, default None\n",
        "        The dict containing the best combination (in term of score) of hyperparameters.\n",
        "    best_score : float, default None\n",
        "        The best score achieved by all the possible combination created.\n",
        "    best_model : TF Model, default None\n",
        "        The best model (in term of score). Accessible only if store_model is set to True. \n",
        "        \n",
        "    \n",
        "    Notes\n",
        "    ----------\n",
        "    KerasRandomSearch allows the usage of every callbacks available in Keras (also the \n",
        "    custom one). The callbacks, that provide the possibility to save any output as\n",
        "    external files, support naming formatting options. This is true for ModelCheckpoint,\n",
        "    CSVLogger, TensorBoard and RemoteMonitor. 'trial' is the custom token that can be used\n",
        "    to personalize the name formatting. \n",
        "    \n",
        "    For example: if filepath in ModelCheckpoint is model_{trial}.hdf5, then the model \n",
        "    checkpoints will be saved with the relative number of trial in the filename.\n",
        "    This enables to save and differentiate each model created in the searching trials. \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 hypermodel,\n",
        "                 param_grid,\n",
        "                 n_iter,\n",
        "                 sampling_seed = 0,\n",
        "                 monitor ='val_loss',\n",
        "                 greater_is_better = False,\n",
        "                 store_model = True,\n",
        "                 savepath = None,\n",
        "                 tuner_verbose = 1):\n",
        "        \n",
        "        self.hypermodel = hypermodel\n",
        "        self.param_grid = param_grid\n",
        "        self.n_iter = n_iter\n",
        "        self.sampling_seed = sampling_seed        \n",
        "        self.monitor = monitor\n",
        "        self.greater_is_better = greater_is_better\n",
        "        self.store_model = store_model\n",
        "        self.savepath = savepath\n",
        "        self.tuner_verbose = tuner_verbose\n",
        "        self.trials = []\n",
        "        self.scores = []\n",
        "        self.best_params = None\n",
        "        self.best_score = None\n",
        "        self.best_model = None\n",
        "        \n",
        "        \n",
        "    def set_seed(self,\n",
        "                 seed_fun,\n",
        "                 **seedargs):\n",
        "        \n",
        "        \"\"\"\n",
        "        Pass a function to set the seed in every trial: optional.\n",
        "        \n",
        "        Parameters\n",
        "        ---------- \n",
        "        seed_fun : callable, default None\n",
        "            Function used to set the seed in each trial.\n",
        "        seedargs : Additional arguments of seed_fun.\n",
        "            \n",
        "        Examples\n",
        "        --------\n",
        "        >>> def seed_setter(seed):\n",
        "        >>>     tf.random.set_seed(seed)\n",
        "        >>>     os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "        >>>     np.random.seed(seed)\n",
        "        >>>     random.seed(seed)\n",
        "        >>>\n",
        "        >>> kgs = KerasRandomSearch(...)\n",
        "        >>> kgs.set_seed(seed_setter, seed=1234)\n",
        "        >>> kgs.search(...)\n",
        "        \"\"\"\n",
        "        \n",
        "        if not callable(seed_fun):\n",
        "            raise ValueError(\"seed_fun must be a callable function\")\n",
        "        \n",
        "        self.seed_fun = seed_fun\n",
        "        self.seedargs = seedargs\n",
        "    \n",
        "    \n",
        "    def search(self, \n",
        "               x, \n",
        "               y = None, \n",
        "               validation_data = None, \n",
        "               validation_split = 0.0, \n",
        "               **fitargs):\n",
        "        \n",
        "        \"\"\"\n",
        "        Performs a search for best hyperparameter configurations creating\n",
        "        all the possible trials and evaluating on the validation set provided.\n",
        "        \n",
        "        Parameters\n",
        "        ----------       \n",
        "        x : multi types\n",
        "            Input data. All the input format supported by Keras model are accepted.\n",
        "        y : multi types, default None\n",
        "            Target data. All the target format supported by Keras model are accepted.\n",
        "        validation_data : multi types, default None\n",
        "            Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
        "            All the validation_data format supported by Keras model are accepted.\n",
        "        validation_split : float, default 0.0\n",
        "            Float between 0 and 1. Fraction of the training data to be used as validation data.\n",
        "        **fitargs : Additional fitting arguments, the same accepted in Keras model.fit(...).\n",
        "        \"\"\"\n",
        "        \n",
        "        # retrive utility params from CV process (if applied)\n",
        "        fold = self._fold if hasattr(self, '_fold') else ''\n",
        "        callback_paths = (self._callback_paths if hasattr(self, '_callback_paths') \n",
        "                          else '')\n",
        "        \n",
        "        if validation_data is None and validation_split == 0.0:\n",
        "            raise ValueError(\"Pass at least one of validation_data or validation_split\")\n",
        "            \n",
        "        if not isinstance(self.param_grid, dict):\n",
        "            raise ValueError(\"Pass param_grid in dict format\")\n",
        "        self.param_grid = self.param_grid.copy()\n",
        "        \n",
        "        tunable_fitargs = ['batch_size', 'epochs', 'steps_per_epoch', 'class_weight']\n",
        "            \n",
        "        if 'callbacks' in fitargs.keys() and fold == '':\n",
        "            callback_paths = _get_callback_paths(fitargs['callbacks'])\n",
        "        \n",
        "        start_score = -np.inf if self.greater_is_better else np.inf\n",
        "        self.best_score = start_score \n",
        "\n",
        "        eval_epoch = np.argmax if self.greater_is_better else np.argmin\n",
        "        eval_score = np.max if self.greater_is_better else np.min\n",
        "        \n",
        "        verbose = fitargs['verbose'] if 'verbose' in fitargs.keys() else 0\n",
        "                \n",
        "        rs = ParameterSampler(n_iter = self.n_iter, \n",
        "                              param_distributions = self.param_grid,\n",
        "                              random_state = self.sampling_seed)\n",
        "        sampled_params = rs.sample()\n",
        "        \n",
        "        if self.tuner_verbose == 1:\n",
        "            print(f\"\\n{self.n_iter} trials detected for {tuple(self.param_grid.keys())}\")\n",
        "                \n",
        "        for trial,param in enumerate(sampled_params):\n",
        "            \n",
        "            if hasattr(self, 'seed_fun'):\n",
        "                self.seed_fun(**self.seedargs)\n",
        "                \n",
        "            if 'callbacks' in fitargs.keys():\n",
        "                fitargs['callbacks'] = _clear_callbacks(fitargs['callbacks'], \n",
        "                                                        callback_paths,\n",
        "                                                        trial+1, fold,\n",
        "                                                        start_score)\n",
        "            \n",
        "            param = dict(zip(self.param_grid.keys(), param))\n",
        "            model = self.hypermodel(param)\n",
        "            \n",
        "            fit_param = {k:v for k,v in param.items() if k in tunable_fitargs} \n",
        "            all_fitargs = dict(list(fitargs.items()) + list(fit_param.items()))\n",
        "            \n",
        "            if self.tuner_verbose == 1:\n",
        "                print(f\"\\n***** ({trial+1}/{self.n_iter}) *****\\nSearch({param})\")\n",
        "            else:\n",
        "                verbose = 0\n",
        "            all_fitargs['verbose'] = verbose\n",
        "                        \n",
        "            model.fit(x = x, \n",
        "                      y = y, \n",
        "                      validation_split = validation_split, \n",
        "                      validation_data = validation_data,\n",
        "                      **all_fitargs)\n",
        "                                    \n",
        "            epoch = eval_epoch(model.history.history[self.monitor])\n",
        "            param['epochs'] = epoch+1\n",
        "            param['steps_per_epoch'] = model.history.params['steps']\n",
        "            param['batch_size'] = (all_fitargs['batch_size'] if 'batch_size' \n",
        "                                   in all_fitargs.keys() else None)\n",
        "            score = np.round(model.history.history[self.monitor][epoch],5)\n",
        "            evaluate = eval_score([self.best_score, score])\n",
        "                    \n",
        "            if self.best_score != evaluate:\n",
        "\n",
        "                self.best_params = param\n",
        "\n",
        "                if self.store_model:\n",
        "                    self.best_model = model\n",
        "\n",
        "                if self.savepath is not None:\n",
        "                    model.save(self.savepath.format(fold=fold))\n",
        "            \n",
        "            self.best_score = evaluate\n",
        "            self.trials.append(param)\n",
        "            self.scores.append(score)\n",
        "            \n",
        "            if self.tuner_verbose == 1:\n",
        "                print(f\"SCORE: {score} at epoch {epoch+1}\")\n",
        "                \n",
        "\n",
        "\n",
        "class KerasGridSearchCV(object):\n",
        "    \n",
        "    \"\"\"\n",
        "    Grid hyperparamater searching and optimization with cross-validation.\n",
        "    \n",
        "    Pass a Keras model (in Sequential or Functional format), and \n",
        "    a dictionary with the parameter boundaries for the experiment.\n",
        "    The cross-validation strategies are the same provided by the \n",
        "    scikit-learn cross-validation generator.\n",
        "    \n",
        "    For searching, takes in the same arguments available in Keras model.fit(...).\n",
        "    Only input in array format are supported. In case of multi-input or\n",
        "    multi-output is it possible to wrap arrays in list or dictionaries like in\n",
        "    Keras.\n",
        "    \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    hypermodel : function\n",
        "        A callable that takes parameters in dict format and returns a TF Model instance.\n",
        "    param_grid : dict\n",
        "        Hyperparameters to try, 1-to-1 mapped with the parameters dict keys present \n",
        "        in the hypermodel function.\n",
        "    cv : scikit-learn cross-validation generator\n",
        "        An sklearn.model_selection splitter class. Used to determine how samples \n",
        "        are split up into groups for cross-validation.\n",
        "    monitor : str, default val_loss\n",
        "        Quantity to monitor in order to detect the best models.\n",
        "    greater_is_better : bool, default False\n",
        "        Whether the quantity to monitor is a score function, meaning high is good, \n",
        "        or a loss function (as default), meaning low is good.\n",
        "    store_model : bool, default True\n",
        "        If True the best models are stored inside the KerasGridSearchCV object. The best model\n",
        "        of each fold is stored.\n",
        "    savepath : str, default None\n",
        "        String or path-like, path to save the best model files. If None, no saving is applied. \n",
        "        savepath can contain named formatting options ('fold' is a special useful key). \n",
        "        For example: if filepath is model_{fold}.h5, then the best model of each fold is saved \n",
        "        with the number of the relative fold in the name.\n",
        "    tuner_verbose : int, default 1\n",
        "        0 or 1. Verbosity mode. 0 = silent, 1 = print trial logs with the connected score.\n",
        "        \n",
        "        \n",
        "    Attributes\n",
        "    ----------\n",
        "    folds_trials : dict\n",
        "        A dicts of list. The lists contain all the hyperparameter combinations tried \n",
        "        in each fold and derived from the param_grid. \n",
        "    folds_scores : dict\n",
        "        A dicts of list. The lists contain the monitor quantities achived on the \n",
        "        validation data by all the models tried in each fold.\n",
        "    folds_best_params : dict\n",
        "        The dict containing the best combination (in term of score) of hyperparameters \n",
        "        in each fold.\n",
        "    folds_best_score : dict\n",
        "        The best scores achieved by all the possible combination created in each fold.\n",
        "    folds_best_model : dict\n",
        "        The best models (in term of score) in each fold. Accessible only if store_model \n",
        "        is set to True. \n",
        "    best_params_score : float, default None\n",
        "        The best average score in all the available folds.\n",
        "    best_params : dict, default None\n",
        "        The paramareter combination related to the best average score \n",
        "        in all the available folds.\n",
        "    \n",
        "    Notes\n",
        "    ----------\n",
        "    KerasGridSearchCV allows the usage of every callbacks available in Keras (also the \n",
        "    custom one). The callbacks, that provide the possibility to save any output as\n",
        "    external files, support naming formatting options. This is true for ModelCheckpoint,\n",
        "    CSVLogger, TensorBoard and RemoteMonitor. 'trial' and 'fold' are custom tokens that \n",
        "    can be used to personalize the name formatting. \n",
        "    \n",
        "    For example: if filepath in ModelCheckpoint is model_{fold}_{trial}.hdf5, then \n",
        "    the model checkpoints will be saved with the relative number of trial, obtained at\n",
        "    a certain fold, in the filename. This enables to save and differentiate each model \n",
        "    created in the searching trials. \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 hypermodel,\n",
        "                 param_grid,\n",
        "                 cv,\n",
        "                 monitor = 'val_loss',\n",
        "                 greater_is_better = False,\n",
        "                 store_model = True,\n",
        "                 savepath = None,\n",
        "                 tuner_verbose = 1):\n",
        "        \n",
        "        self.hypermodel = hypermodel\n",
        "        self.param_grid = param_grid\n",
        "        self.cv = cv\n",
        "        self.monitor = monitor\n",
        "        self.greater_is_better = greater_is_better\n",
        "        self.store_model = store_model\n",
        "        self.savepath = savepath\n",
        "        self.tuner_verbose = tuner_verbose\n",
        "        self.folds_trials = {}\n",
        "        self.folds_scores = {}\n",
        "        self.folds_best_params = {}\n",
        "        self.folds_best_score = {}\n",
        "        self.folds_best_models = {}\n",
        "        self.best_params_score = None\n",
        "        self.best_params = None\n",
        "        \n",
        "        \n",
        "    def set_seed(self,\n",
        "                 seed_fun,\n",
        "                 **seedargs):\n",
        "        \n",
        "        \"\"\"\n",
        "        Pass a function to set the seed in every trial: optional.\n",
        "        \n",
        "        Parameters\n",
        "        ---------- \n",
        "        seed_fun : callable, default None\n",
        "            Function used to set the seed in each trial.\n",
        "        seedargs : Additional arguments of seed_fun.\n",
        "            \n",
        "        Examples\n",
        "        --------\n",
        "        >>> def seed_setter(seed):\n",
        "        >>>     tf.random.set_seed(seed)\n",
        "        >>>     os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "        >>>     np.random.seed(seed)\n",
        "        >>>     random.seed(seed)\n",
        "        >>>\n",
        "        >>> kgs = KerasGridSearchCV(...)\n",
        "        >>> kgs.set_seed(seed_setter, seed=1234)\n",
        "        >>> kgs.search(...)\n",
        "        \"\"\"\n",
        "\n",
        "        if not callable(seed_fun):\n",
        "            raise ValueError(\"seed_fun must be a callable function\")\n",
        "        \n",
        "        self.seed_fun = seed_fun\n",
        "        self.seedargs = seedargs\n",
        "        \n",
        "        \n",
        "    def search(self, \n",
        "               x, \n",
        "               y, \n",
        "               sample_weight = None, \n",
        "               groups = None, \n",
        "               **fitargs): \n",
        "        \n",
        "        \"\"\"\n",
        "        Performs a search for best hyperparameter configurations creating\n",
        "        all the possible trials and evaluating on the validation folder created\n",
        "        following the validation strategy.\n",
        "        \n",
        "        Parameters\n",
        "        ----------       \n",
        "        x : multi types\n",
        "            Input data. Accepted types are arrays or list/dict in case of multi-input/output.\n",
        "        y : multi types, default None\n",
        "            Target data. Accepted types are arrays or list/dict in case of multi-input/output.\n",
        "        sample_weight : multi types, default None\n",
        "            Optional Numpy array of weights for the training samples, used for weighting \n",
        "            the loss function (during training only). Accepted types are arrays or \n",
        "            list/dict in case of multi-input/output\n",
        "        groups : array-like, default None\n",
        "            Group labels for the samples used while splitting the dataset into train/valid set.\n",
        "        **fitargs : Additional fitting arguments, the same accepted in Keras model.fit(...).\n",
        "            The validation set is automatically created accordingly the cv strategy.\n",
        "        \"\"\"\n",
        "                \n",
        "        if 'validation_split' in fitargs.keys() or 'validation_data' in fitargs.keys():\n",
        "            raise ValueError(\"Validation is automatically created by the cv strategy\")\n",
        "        \n",
        "        _check_data(x)\n",
        "        _check_data(y)\n",
        "        if sample_weight is not None: _check_data(sample_weight)\n",
        "        \n",
        "        for fold,(train_id,val_id) in enumerate(self.cv.split(x, y, groups)):\n",
        "            \n",
        "            if self.tuner_verbose == 1:\n",
        "                print(\"\\n{}\\n{}  Fold {}  {}\\n{}\".format(\n",
        "                    '#'*18, '#'*3, str(fold+1).zfill(3), '#'*3, '#'*18))\n",
        "            \n",
        "            if 'callbacks' in fitargs.keys() and fold == 0:\n",
        "                callback_paths = _get_callback_paths(fitargs['callbacks'])\n",
        "                            \n",
        "            x_train = _create_fold(x, train_id)\n",
        "            y_train = _create_fold(y, train_id)\n",
        "            sample_weight_train = (_create_fold(sample_weight, train_id) if sample_weight \n",
        "                                   is not None else None)\n",
        "            \n",
        "            x_val = _create_fold(x, val_id)\n",
        "            y_val = _create_fold(y, val_id)\n",
        "            sample_weight_val = (_create_fold(sample_weight, val_id) if sample_weight \n",
        "                                 is not None else None)\n",
        "        \n",
        "            kgs_fold = KerasGridSearch(hypermodel = self.hypermodel,   \n",
        "                                       param_grid = self.param_grid,\n",
        "                                       monitor = self.monitor,\n",
        "                                       greater_is_better = self.greater_is_better,\n",
        "                                       store_model = self.store_model,\n",
        "                                       savepath = self.savepath,\n",
        "                                       tuner_verbose = self.tuner_verbose)\n",
        "            \n",
        "            kgs_fold._fold = fold+1\n",
        "            if 'callbacks' in fitargs.keys():\n",
        "                kgs_fold._callback_paths = callback_paths\n",
        "            \n",
        "            if hasattr(self, 'seed_fun'):\n",
        "                kgs_fold.set_seed(self.seed_fun, **self.seedargs)\n",
        "\n",
        "            kgs_fold.search(x = x_train, \n",
        "                            y = y_train, \n",
        "                            sample_weight = sample_weight_train,\n",
        "                            validation_data = (x_val, y_val, sample_weight_val),\n",
        "                            **fitargs)\n",
        "                                    \n",
        "            self.folds_trials[f\"fold {fold+1}\"] = kgs_fold.trials\n",
        "            self.folds_scores[f\"fold {fold+1}\"] = kgs_fold.scores\n",
        "            self.folds_best_params[f\"fold {fold+1}\"] = kgs_fold.best_params\n",
        "            if self.store_model:\n",
        "                self.folds_best_models[f\"fold {fold+1}\"] = kgs_fold.best_model\n",
        "            self.folds_best_score[f\"fold {fold+1}\"] = kgs_fold.best_score\n",
        "            \n",
        "        eval_score = np.argmax if self.greater_is_better else np.argmin\n",
        "        mean_score_params = np.mean(list(self.folds_scores.values()), axis=0).round(5)\n",
        "        evaluate = eval_score(mean_score_params)\n",
        "        \n",
        "        self.best_params = [list(f)[evaluate] for f in self.folds_trials.values()]\n",
        "        self.best_params_score = mean_score_params[evaluate]\n",
        "        \n",
        "        \n",
        "        \n",
        "class KerasRandomSearchCV(object):\n",
        "    \n",
        "    \"\"\"\n",
        "    Random hyperparamater searching and optimization with cross-validation.\n",
        "    \n",
        "    Pass a Keras model (in Sequential or Functional format), and \n",
        "    a dictionary with the parameter boundaries for the experiment.\n",
        "    The cross-validation strategies are the same provided by the \n",
        "    scikit-learn cross-validation generator.\n",
        "    \n",
        "    In contrast to grid-search, not all parameter values are tried out, \n",
        "    but rather a fixed number of parameter settings is sampled from \n",
        "    the specified distributions. The number of parameter settings that \n",
        "    are tried is given by n_iter.\n",
        "    If all parameters are presented as a list, sampling without replacement \n",
        "    is performed. If at least one parameter is given as a distribution \n",
        "    (random variable from scipy.stats.distribution), sampling with replacement \n",
        "    is used. It is highly recommended to use continuous distributions \n",
        "    for continuous parameters.\n",
        "    \n",
        "    For searching, takes in the same arguments available in Keras model.fit(...).\n",
        "    Only input in array format are supported. In case of multi-input or\n",
        "    multi-output is it possible to wrap arrays in list or dictionaries like in\n",
        "    Keras.\n",
        "    \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    hypermodel : function\n",
        "        A callable that takes parameters in dict format and returns a TF Model instance.\n",
        "    param_grid : dict\n",
        "        Hyperparameters to try, 1-to-1 mapped with the parameters dict keys present \n",
        "        in the hypermodel function.\n",
        "    cv : scikit-learn cross-validation generator\n",
        "        An sklearn.model_selection splitter class. Used to determine how samples \n",
        "        are split up into groups for cross-validation.\n",
        "    n_iter : int\n",
        "        Number of parameter settings that are sampled. \n",
        "        n_iter trades off runtime vs quality of the solution.\n",
        "    sampling_seed : int, default 0\n",
        "        The seed used to sample from the hyperparameter distributions.\n",
        "    monitor : str, default val_loss\n",
        "        Quantity to monitor in order to detect the best models.\n",
        "    greater_is_better : bool, default False\n",
        "        Whether the quantity to monitor is a score function, meaning high is good, \n",
        "        or a loss function (as default), meaning low is good.\n",
        "    store_model : bool, default True\n",
        "        If True the best models are stored inside the KerasRandomSearchCV object. The best model\n",
        "        of each fold is stored.\n",
        "    savepath : str, default None\n",
        "        String or path-like, path to save the best model files. If None, no saving is applied. \n",
        "        savepath can contain named formatting options ('fold' is a special useful key). \n",
        "        For example: if filepath is model_{fold}.h5, then the best model of each fold is saved \n",
        "        with the number of the relative fold in the name.\n",
        "    tuner_verbose : int, default 1\n",
        "        0 or 1. Verbosity mode. 0 = silent, 1 = print trial logs with the connected score.\n",
        "        \n",
        "        \n",
        "    Attributes\n",
        "    ----------\n",
        "    folds_trials : dict\n",
        "        A dicts of list. The lists contain all the hyperparameter combinations tried \n",
        "        in each fold and derived from the param_grid. \n",
        "    folds_scores : dict\n",
        "        A dicts of list. The lists contain the monitor quantities achived on the \n",
        "        validation data by all the models tried in each fold.\n",
        "    folds_best_params : dict\n",
        "        The dict containing the best combination (in term of score) of hyperparameters \n",
        "        in each fold.\n",
        "    folds_best_score : dict\n",
        "        The best scores achieved by all the possible combination created in each fold.\n",
        "    folds_best_model : dict\n",
        "        The best models (in term of score) in each fold. Accessible only if store_model \n",
        "        is set to True. \n",
        "    best_params_score : float, default None\n",
        "        The best average score in all the available folds.\n",
        "    best_params : dict, default None\n",
        "        The paramareter combination related to the best average score \n",
        "        in all the available folds.\n",
        "    \n",
        "    Notes\n",
        "    ----------\n",
        "    KerasRandomSearchCV allows the usage of every callbacks available in keras (also the \n",
        "    custom one). The callbacks, that provide the possibility to save any output as\n",
        "    external files, support naming formatting options. This is true for ModelCheckpoint,\n",
        "    CSVLogger, TensorBoard and RemoteMonitor. 'trial' and 'fold' are custom tokens that \n",
        "    can be used to personalize the name formatting. \n",
        "    \n",
        "    For example: if filepath in ModelCheckpoint is model_{fold}_{trial}.hdf5, then \n",
        "    the model checkpoints will be saved with the relative number of trial, obtained at\n",
        "    a certain fold, in the filename. This enables to save and differentiate each model \n",
        "    created in the searching trials. \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 hypermodel,\n",
        "                 param_grid,\n",
        "                 cv,\n",
        "                 n_iter,\n",
        "                 sampling_seed = 0,\n",
        "                 monitor = 'val_loss',\n",
        "                 greater_is_better = False,\n",
        "                 store_model = True,\n",
        "                 savepath = None,\n",
        "                 tuner_verbose = 1):\n",
        "        \n",
        "        self.hypermodel = hypermodel\n",
        "        self.param_grid = param_grid\n",
        "        self.cv = cv\n",
        "        self.n_iter = n_iter\n",
        "        self.sampling_seed = sampling_seed\n",
        "        self.monitor = monitor\n",
        "        self.greater_is_better = greater_is_better\n",
        "        self.store_model = store_model\n",
        "        self.savepath = savepath\n",
        "        self.tuner_verbose = tuner_verbose\n",
        "        self.folds_trials = {}\n",
        "        self.folds_scores = {}\n",
        "        self.folds_best_params = {}\n",
        "        self.folds_best_score = {}\n",
        "        self.folds_best_models = {}\n",
        "        self.best_params_score = None\n",
        "        self.best_params = None\n",
        "        \n",
        "        \n",
        "    def set_seed(self,\n",
        "                 seed_fun,\n",
        "                 **seedargs):\n",
        "        \n",
        "        \"\"\"\n",
        "        Pass a function to set the seed in every trial: optional.\n",
        "        \n",
        "        Parameters\n",
        "        ---------- \n",
        "        seed_fun : callable, default None\n",
        "            Function used to set the seed in each trial.\n",
        "        seedargs : Additional arguments of seed_fun.\n",
        "            \n",
        "        Examples\n",
        "        --------\n",
        "        >>> def seed_setter(seed):\n",
        "        >>>     tf.random.set_seed(seed)\n",
        "        >>>     os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "        >>>     np.random.seed(seed)\n",
        "        >>>     random.seed(seed)\n",
        "        >>>\n",
        "        >>> kgs = KerasRandomSearchCV(...)\n",
        "        >>> kgs.set_seed(seed_setter, seed=1234)\n",
        "        >>> kgs.search(...)\n",
        "        \"\"\"\n",
        "\n",
        "        if not callable(seed_fun):\n",
        "            raise ValueError(\"seed_fun must be a callable function\")\n",
        "        \n",
        "        self.seed_fun = seed_fun\n",
        "        self.seedargs = seedargs\n",
        "        \n",
        "        \n",
        "    def search(self, \n",
        "               x, \n",
        "               y, \n",
        "               sample_weight = None, \n",
        "               groups = None, \n",
        "               **fitargs): \n",
        "        \n",
        "        \"\"\"\n",
        "        Performs a search for best hyperparameter configurations creating\n",
        "        all the possible trials and evaluating on the validation folder created\n",
        "        following the validation strategy.\n",
        "        \n",
        "        Parameters\n",
        "        ----------       \n",
        "        x : multi types\n",
        "            Input data. Accepted types are arrays or list/dict in case of multi-input/output.\n",
        "        y : multi types, default None\n",
        "            Target data. Accepted types are arrays or list/dict in case of multi-input/output.\n",
        "        sample_weight : multi types, default None\n",
        "            Optional Numpy array of weights for the training samples, used for weighting \n",
        "            the loss function (during training only). Accepted types are arrays or \n",
        "            list/dict in case of multi-input/output\n",
        "        groups : array-like, default None\n",
        "            Group labels for the samples used while splitting the dataset into train/valid set.\n",
        "        **fitargs : Additional fitting arguments, the same accepted in Keras model.fit(...).\n",
        "            The validation set is automatically created accordingly the cv strategy.\n",
        "        \"\"\"\n",
        "                \n",
        "        if 'validation_split' in fitargs.keys() or 'validation_data' in fitargs.keys():\n",
        "            raise ValueError(\"Validation is automatically created by the cv strategy\")\n",
        "        \n",
        "        _check_data(x)\n",
        "        _check_data(y)\n",
        "        if sample_weight is not None: _check_data(sample_weight)\n",
        "        \n",
        "        for fold,(train_id,val_id) in enumerate(self.cv.split(x, y, groups)):\n",
        "            \n",
        "            if self.tuner_verbose == 1:\n",
        "                print(\"\\n{}\\n{}  Fold {}  {}\\n{}\".format(\n",
        "                    '#'*18, '#'*3, str(fold+1).zfill(3), '#'*3, '#'*18))\n",
        "            \n",
        "            if 'callbacks' in fitargs.keys() and fold == 0:\n",
        "                callback_paths = _get_callback_paths(fitargs['callbacks'])\n",
        "                            \n",
        "            x_train = _create_fold(x, train_id)\n",
        "            y_train = _create_fold(y, train_id)\n",
        "            sample_weight_train = (_create_fold(sample_weight, train_id) if sample_weight \n",
        "                                   is not None else None)\n",
        "            \n",
        "            x_val = _create_fold(x, val_id)\n",
        "            y_val = _create_fold(y, val_id)\n",
        "            sample_weight_val = (_create_fold(sample_weight, val_id) if sample_weight \n",
        "                                 is not None else None)\n",
        "                        \n",
        "            kgs_fold = KerasRandomSearch(hypermodel = self.hypermodel,   \n",
        "                                         param_grid = self.param_grid,\n",
        "                                         n_iter = self.n_iter,\n",
        "                                         sampling_seed = self.sampling_seed,\n",
        "                                         monitor = self.monitor,\n",
        "                                         greater_is_better = self.greater_is_better,\n",
        "                                         store_model = self.store_model,\n",
        "                                         savepath = self.savepath,\n",
        "                                         tuner_verbose = self.tuner_verbose)\n",
        "            \n",
        "            kgs_fold._fold = fold+1\n",
        "            if 'callbacks' in fitargs.keys():\n",
        "                kgs_fold._callback_paths = callback_paths\n",
        "            \n",
        "            if hasattr(self, 'seed_fun'):\n",
        "                kgs_fold.set_seed(self.seed_fun, **self.seedargs)\n",
        "\n",
        "            kgs_fold.search(x = x_train, \n",
        "                            y = y_train, \n",
        "                            sample_weight = sample_weight_train,\n",
        "                            validation_data = (x_val, y_val, sample_weight_val),\n",
        "                            **fitargs)\n",
        "                                    \n",
        "            self.folds_trials[f\"fold {fold+1}\"] = kgs_fold.trials\n",
        "            self.folds_scores[f\"fold {fold+1}\"] = kgs_fold.scores\n",
        "            self.folds_best_params[f\"fold {fold+1}\"] = kgs_fold.best_params\n",
        "            if self.store_model:\n",
        "                self.folds_best_models[f\"fold {fold+1}\"] = kgs_fold.best_model\n",
        "            self.folds_best_score[f\"fold {fold+1}\"] = kgs_fold.best_score\n",
        "            \n",
        "        eval_score = np.argmax if self.greater_is_better else np.argmin\n",
        "        mean_score_params = np.mean(list(self.folds_scores.values()), axis=0).round(5)\n",
        "        evaluate = eval_score(mean_score_params)\n",
        "        \n",
        "        self.best_params = [list(f)[evaluate] for f in self.folds_trials.values()]\n",
        "        self.best_params_score = mean_score_params[evaluate]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKlmjXsM6-PQ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd   \n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.callbacks import * \n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocAh6JwZ7KjX"
      },
      "source": [
        "class T2V(Layer):\n",
        "    \n",
        "    def __init__(self, output_dim=None, **kwargs):\n",
        "        self.output_dim = output_dim\n",
        "        super(T2V, self).__init__(**kwargs)\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.W = self.add_weight(name='W',\n",
        "                                shape=(1, self.output_dim),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "\n",
        "        self.P = self.add_weight(name='P',\n",
        "                                shape=(1, self.output_dim),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "\n",
        "        self.w = self.add_weight(name='w',\n",
        "                                shape=(1, 1),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "\n",
        "        self.p = self.add_weight(name='p',\n",
        "                                shape=(1, 1),\n",
        "                                initializer='uniform',\n",
        "                                trainable=True)\n",
        "\n",
        "        super(T2V, self).build(input_shape)\n",
        "        \n",
        "    def call(self, x):\n",
        "        \n",
        "        original = self.w * x + self.p\n",
        "        sin_trans = K.sin(K.dot(x, self.W) + self.P)\n",
        "        \n",
        "        return K.concatenate([sin_trans, original], -1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H_-Y25Z7OrF"
      },
      "source": [
        "sequence_length = 24\n",
        "\n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    \n",
        "    data_matrix = id_df[seq_cols].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_matrix[start:stop, :]\n",
        "\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    \n",
        "    data_matrix = id_df[label].values\n",
        "    num_elements = data_matrix.shape[0]\n",
        "    \n",
        "    return data_matrix[seq_length:num_elements, :]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqf-K6fa7Rx7"
      },
      "source": [
        "def set_seed_TF2(seed):\n",
        "    \n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    \n",
        "\n",
        "def T2V_NN(param, dim):\n",
        "    \n",
        "    inp = Input(shape=(dim,1))\n",
        "    x = T2V(param['t2v_dim'])(inp)\n",
        "    x = LSTM(param['unit'], activation=param['act'])(x)\n",
        "    x = Dense(1)(x)\n",
        "    \n",
        "    m = Model(inp, x)\n",
        "    m.compile(loss='mse', optimizer=Adam(lr=param['lr']))\n",
        "    \n",
        "    return m\n",
        "\n",
        "\n",
        "def NN(param, dim):\n",
        "    \n",
        "    inp = Input(shape=(dim,1))\n",
        "    x = LSTM(param['unit'], activation=param['act'])(inp)\n",
        "    x = Dense(1)(x)\n",
        "    \n",
        "    m = Model(inp, x)\n",
        "    m.compile(loss='mse', optimizer=Adam(lr=param['lr']))\n",
        "    \n",
        "    return m"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT4wpS3w7V8I"
      },
      "source": [
        "X, Y = [], []\n",
        "for sequence in gen_sequence(bmi_obeso, sequence_length, ['Value']):\n",
        "    X.append(sequence)\n",
        "    \n",
        "for sequence in gen_labels(bmi_obeso, sequence_length, ['Value']):\n",
        "    Y.append(sequence)\n",
        "    \n",
        "X = np.asarray(X)\n",
        "Y = np.asarray(Y)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ew2h0Gp7l7f",
        "outputId": "22d33b81-79f7-41db-9630-befa35324c4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dim = int(0.7*len(bmi_obeso))\n",
        "X_train, X_test = X[:train_dim], X[train_dim:]\n",
        "y_train, y_test = Y[:train_dim], Y[train_dim:]\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(71970, 24, 1) (71970, 1)\n",
            "(30821, 24, 1) (30821, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_jls2TI7x4t"
      },
      "source": [
        "param_grid = {\n",
        "    'unit': [64,32],\n",
        "    't2v_dim': [128,64],\n",
        "    'lr': [1e-2,1e-3], \n",
        "    'act': ['elu','relu'], \n",
        "    'epochs': 200,\n",
        "    'batch_size': [512,1024]\n",
        "}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMn6Gpaz71Mh",
        "outputId": "b19d257d-8dbe-44c6-e100-d11f42486e04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "es = EarlyStopping(patience=5, verbose=0, min_delta=0.001, monitor='val_loss', mode='auto', restore_best_weights=True)\n",
        "\n",
        "hypermodel = lambda x: T2V_NN(param=x, dim=sequence_length)\n",
        "\n",
        "kgs_t2v = KerasGridSearch(hypermodel, param_grid, monitor='val_loss', greater_is_better=False, tuner_verbose=1)\n",
        "kgs_t2v.set_seed(set_seed_TF2, seed=33)\n",
        "kgs_t2v.search(X_train, y_train, validation_split=0.2, callbacks=[es], shuffle=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "32 trials detected for ('unit', 't2v_dim', 'lr', 'act', 'epochs', 'batch_size')\n",
            "\n",
            "***** (1/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 128, 'lr': 0.01, 'act': 'relu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 3.15414 at epoch 13\n",
            "\n",
            "***** (2/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 128, 'lr': 0.01, 'act': 'relu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.11855 at epoch 25\n",
            "\n",
            "***** (3/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 128, 'lr': 0.01, 'act': 'elu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 2.67437 at epoch 15\n",
            "\n",
            "***** (4/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 128, 'lr': 0.01, 'act': 'elu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 47.10189 at epoch 5\n",
            "\n",
            "***** (5/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 128, 'lr': 0.001, 'act': 'relu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 2.23134 at epoch 14\n",
            "\n",
            "***** (6/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 128, 'lr': 0.001, 'act': 'relu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.09508 at epoch 32\n",
            "\n",
            "***** (7/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 128, 'lr': 0.001, 'act': 'elu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 1.97091 at epoch 13\n",
            "\n",
            "***** (8/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 128, 'lr': 0.001, 'act': 'elu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.05352 at epoch 29\n",
            "\n",
            "***** (9/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 64, 'lr': 0.01, 'act': 'relu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 4.27477 at epoch 11\n",
            "\n",
            "***** (10/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 64, 'lr': 0.01, 'act': 'relu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.70734 at epoch 11\n",
            "\n",
            "***** (11/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 64, 'lr': 0.01, 'act': 'elu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 2.17303 at epoch 20\n",
            "\n",
            "***** (12/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 64, 'lr': 0.01, 'act': 'elu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 4.35724 at epoch 16\n",
            "\n",
            "***** (13/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 64, 'lr': 0.001, 'act': 'relu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 2.02268 at epoch 17\n",
            "\n",
            "***** (14/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 64, 'lr': 0.001, 'act': 'relu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.10924 at epoch 28\n",
            "\n",
            "***** (15/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 64, 'lr': 0.001, 'act': 'elu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 2.01837 at epoch 27\n",
            "\n",
            "***** (16/32) *****\n",
            "Search({'unit': 64, 't2v_dim': 64, 'lr': 0.001, 'act': 'elu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.34842 at epoch 13\n",
            "\n",
            "***** (17/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 128, 'lr': 0.01, 'act': 'relu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 15.10694 at epoch 1\n",
            "\n",
            "***** (18/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 128, 'lr': 0.01, 'act': 'relu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.08162 at epoch 37\n",
            "\n",
            "***** (19/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 128, 'lr': 0.01, 'act': 'elu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 2.44596 at epoch 11\n",
            "\n",
            "***** (20/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 128, 'lr': 0.01, 'act': 'elu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.70678 at epoch 34\n",
            "\n",
            "***** (21/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 128, 'lr': 0.001, 'act': 'relu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 2.16107 at epoch 14\n",
            "\n",
            "***** (22/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 128, 'lr': 0.001, 'act': 'relu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.06131 at epoch 36\n",
            "\n",
            "***** (23/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 128, 'lr': 0.001, 'act': 'elu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 2.15222 at epoch 19\n",
            "\n",
            "***** (24/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 128, 'lr': 0.001, 'act': 'elu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.2743 at epoch 16\n",
            "\n",
            "***** (25/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 64, 'lr': 0.01, 'act': 'relu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 2.23881 at epoch 21\n",
            "\n",
            "***** (26/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 64, 'lr': 0.01, 'act': 'relu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.08156 at epoch 7\n",
            "\n",
            "***** (27/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 64, 'lr': 0.01, 'act': 'elu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 2.06583 at epoch 33\n",
            "\n",
            "***** (28/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 64, 'lr': 0.01, 'act': 'elu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.04351 at epoch 23\n",
            "\n",
            "***** (29/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 64, 'lr': 0.001, 'act': 'relu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 2.21968 at epoch 13\n",
            "\n",
            "***** (30/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 64, 'lr': 0.001, 'act': 'relu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.09188 at epoch 26\n",
            "\n",
            "***** (31/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 64, 'lr': 0.001, 'act': 'elu', 'epochs': 200, 'batch_size': 512})\n",
            "SCORE: 2.04964 at epoch 19\n",
            "\n",
            "***** (32/32) *****\n",
            "Search({'unit': 32, 't2v_dim': 64, 'lr': 0.001, 'act': 'elu', 'epochs': 200, 'batch_size': 1024})\n",
            "SCORE: 2.01638 at epoch 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3aNH_dy74U9",
        "outputId": "801542a4-d57b-4acf-f751-bad2c696abfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pred_t2v = kgs_t2v.best_model.predict(X_test).ravel()\n",
        "mean_absolute_error(y_test.ravel(), pred_t2v)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36795937706566206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8n5-gSNwY28",
        "outputId": "010ab437-6853-4bec-f30d-c8647167406a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "\n",
        "plt.plot(pred_t2v[:730], label='prediction')\n",
        "plt.plot(y_test.ravel()[:730], label='true')\n",
        "plt.title('T2V plus LSTM'); plt.legend()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4041668ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAE/CAYAAACevBBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUVf7H8fd3JpMCIQFC6C0UAQHpIAKiYkFFxF3QtWLvbe111/rTde19EVcsoAji2gERsIvSpHdCh4RQA2kz9/z+uHcmnSSQzCTc7+t5eJi5c+6dMyHM555zzz1HjDEopZRSKrw8ka6AUkop5UYawEoppVQEaAArpZRSEaABrJRSSkWABrBSSikVARrASimlVARoACtVw4lIaxExIhIV6boopcpPA1ipwyAimQX+WCKSVeD5xSIyWkTmicg+EdksIs8EA1JEporIYyUc81wR2V5dglREUkXk1FJee0BE1jufd7OITHS2Ly3wcwiISHaB5w+IyOXOycILRY53rrN9XBg+mlLVggawUofBGBMf/ANsBM4psG08UAu4HWgA9AOGAHc5u78LXCIiUuSwlwLjjTH+8HyKwyMio7Hreqrz+XsD3wEYYzoX+Ln8CNxc4Ofyf84h1gLnFznRGA2sCt+nUCryNICVqgLGmDeMMT8aY3KNMVuA8cAA5+X/AUnAoGB5EakHDAPeK+l4IjJbRJ4Skd+dVvVnIlK/lLKFWq4i8oiIfOA8jhWRD0QkQ0T2iMgfItKogh+vDzDNGLPW+azbjTFjKrD/dmAxcIZTp/rACcDnFayHUjWaBrBS4XEisBTAGJMFfAxcVuD184EVxpg/D3GMy4ArgSaAH3j5MOoxGkgEWmCfBFwPZFXwGL8Bl4nI3SLSW0S8h1GP98j//H8DPgNyDuM4StVYGsBKVTERuRK7m/bZApvfBUaKSKzz/DJn26G8b4xZYow5ADyM3Y1b0fDLww7edsaYgDFmnjFmX0UOYIz5ALgFuwX7PZAmIvdWsB6fAieJSCL2Zy+x5a/U0UwDWKkqJCIjgKeAM40xO4PbjTE/ATuBESLSFugLTCjjcJsKPN4A+LCvMVfE+8A04CMR2eoMDvNV8BgYY8YbY04F6mK3oh8XkTMqsH8W8BXwEJBkjPm5onVQqqbTAFaqiojIUOAt7AFai0soEuyGvQT7muqOMg7ZosDjltit2Z0llDuAPQgsqHHwgTEmzxjzqDHmWOzrrsMo3BVeIc7xJgGLgC4V3P094E7gg8N9f6VqMg1gpaqAiJyCPfDqr8aY30sp9h5wKnANZXc/gz1y+lgRqQU8Bkw2xgRKKLcQ+JuI+ESkNzCyQL1OFpGuTtf1PuwQtw7xnj5n4FbwT5RzK9HZIlJHRDwicibQGZhTjs9Q0PfAacArFdxPqaOCBrBSVeNh7MFOXxe4D/abggWMManAL0BtyjcC+H1gHPYo4ljg1kO8d1tgN/Aohbu2GwOTscN3OXYIvn+I9/wae5BW8M8jzr4PYN9+tQd4BrjB6VYvN2P7zhizqyL7KXW0EGNMpOuglCqDiMwGPjDGjI10XZRSlUNbwEoppVQEaAArpZRSEaBd0EoppVQEaAtYKaWUigANYKWUUioCwrrsWYMGDUzr1q3D+ZZKKaVUxMybN2+nMSa5pNfCGsCtW7dm7ty54XxLpZRSKmJEZENpr2kXtFJKKRUBGsBKKaVUBGgAK6WUUhEQ1mvASimlIi8vL4/NmzeTnZ0d6aocNWJjY2nevDk+X/lX99QAVkopl9m8eTN16tShdevWiEikq1PjGWPIyMhg8+bNpKSklHs/7YJWSimXyc7OJikpScO3kogISUlJFe5R0ABWSikX0vCtXIfz89QAVkopVaPNnj2bYcOGAfD555/z9NNPl1p2z549vP7666HnW7duZeTIkVVex5KUK4BFpK6ITBaRFSKyXET6i0h9EflWRFY7f9er6soqpZRyj0AgUOF9hg8fzn333Vfq60UDuGnTpkyePPmw6nekytsCfgmYaozpCHQDlgP3Ad8ZY9oD3znPa5b0lbBnY6RroZRSrpOamkrHjh25+OKL6dSpEyNHjuTgwYO0bt2ae++9l549ezJp0iSmT59O//796dmzJ6NGjSIzMxOAqVOn0rFjR3r27MmUKVNCxx03bhw333wzADt27OC8886jW7dudOvWjV9++YX77ruPtWvX0r17d+6++25SU1Pp0qULYF8bv+KKK+jatSs9evRg1qxZoWP+5S9/YejQobRv35577rmnUn4GZQawiCQCJwJvAxhjco0xe4BzgXedYu8CIyqlRuH0Wl94sWuka6GUUq60cuVKbrzxRpYvX05CQkKoZZqUlMT8+fM59dRTeeKJJ5gxYwbz58+nd+/ePP/882RnZ3PNNdfwxRdfMG/ePLZv317i8W+99VYGDx7Mn3/+yfz58+ncuTNPP/00bdu2ZeHChfz73/8uVP61115DRFi8eDEffvgho0ePDg2sWrhwIRMnTmTx4sVMnDiRTZs2HfHnL89tSClAOvCOiHQD5gG3AY2MMducMtuBRkdcG6WUUmH16BdLWbZ1X6Ue89imCfzznM5llmvRogUDBgwA4JJLLuHll18G4IILLgDgt99+Y9myZaEyubm59O/fnxUrVpCSkkL79u1D+44ZM6bY8WfOnMl7770HgNfrJTExkd27d5dan59++olbbrkFgI4dO9KqVStWrVoFwJAhQ0hMTLQ/37HHsmHDBlq0aFH2D+MQyhPAUUBP4BZjzBwReYki3c3GGCMipqSdReRa4FqAli1bHlFlK1V25f7CKaWUqpiiI4eDz2vXrg3Y99eedtppfPjhh4XKLVy4MDwVLCAmJib02Ov14vf7j/iY5QngzcBmY8wc5/lk7ADeISJNjDHbRKQJkFbSzsaYMcAYgN69e5cY0mGXvReWfRbpWiilVMSVp6VaVTZu3Mivv/5K//79mTBhAgMHDmTBggWh148//nhuuukm1qxZQ7t27Thw4ABbtmyhY8eOpKamsnbtWtq2bVssoIOGDBnCG2+8we23304gECAzM5M6deqwf//+EssPGjSI8ePHc8opp7Bq1So2btxIhw4dmD9/fpV8/jKvARtjtgObRKSDs2kIsAz4HBjtbBsN1JxE+/pu+NzuZiA2MbJ1UUopl+rQoQOvvfYanTp1Yvfu3dxwww2FXk9OTmbcuHFceOGFHHfccaHu59jYWMaMGcPZZ59Nz549adiwYYnHf+mll5g1axZdu3alV69eLFu2jKSkJAYMGECXLl24++67C5W/8cYbsSyLrl27csEFFzBu3LhCLd/KJsaU3SgVke7AWCAaWAdcgR3eHwMtgQ3A+caYXYc6Tu/evU21WA/4vXNh3Wz7cdMecO3sCFZGKaXCa/ny5XTq1CmidUhNTWXYsGEsWbIkovWoTCX9XEVknjGmd0nlyzUXtDFmIVDSAYZUuIaRNuXa/PAF0qwESj53UkoppaqO+xZjWDQRgKVWK/x42bVlD9bebBonxka4Ykop5R6tW7c+qlq/h8O1U1F6sAh2vqdmHIhoXZRSSrmP+wJY7I8cQ579FCjHZXCllFKqUrkvgOPsKatjJA8QBINBE1gppVR4uS6AjXPbUQx5GJybwDV/lVJKhZnrAjgQUxeAu/OuA0A0fZVSKqyKrkjkVq4LYCw/3wV6MMvqEYpejWCllAqf0gK4MqZ3rElqfgB/ej389EK5ixt/Djn47MdOF7QOwlJKqfApuCRgnz59GDRoEMOHD+fYY48ttDwgwLPPPssjjzwCwNq1axk6dCi9evVi0KBBrFixIkKfoHLU7PuAjYE/nTlAB/4dMtZC3Zbg9ZW+T14OuQU+tg7CUkqp8Hr66adZsmQJCxcuZPbs2Zx99tksWbKElJQUUlNTS93v2muv5c0336R9+/bMmTOHG2+8kZkzZ4av4pWsZgfwj8+GHqZv30jymz2h52Uw/JXS9wnkkGOigfwWsFJKudY398H2xZV7zMZd4cyny128b9++pKSkHLJMZmYmv/zyC6NGjQpty8nJOewqVgc1NoDnr9pAz5lPhJ6vnjWBZID578E5L4OUHK4SKN4CtrQBrJRSERNcfhAgKioKy7JCz7OzswGwLIu6detGZCnCqlJjA3jtnz/Ts8DzE1Y+lf9ky3xo3qvE/aTANeDaMVHkZOsgLKWUi1WgpVpZDrUkYKNGjUhLSyMjI4P4+Hi+/PJLhg4dSkJCAikpKUyaNIlRo0ZhjGHRokV069YtzLWvPDV2EFbr3JUAbDP1Q9vWW43IMVHsWzCl1P3EyiXXCeCGCfb8z+VZEUoppVTlONSSgD6fj3/84x/07duX0047jY4dO4ZeGz9+PG+//TbdunWjc+fOfPZZzVkFtyQ1tgWcV6897/lP41H/ZUyPvoe2nm2sNU0J4GXTgrmcfE4JO1kWHiuPHGMHsEdE7wNWSqkImDBhQqmv3Xrrrdx6663FtqekpDB16tSqrFZY1dgWcHab0/iH/woCeHk3cDoAufjYbJJJ8u8oeaeAfcE+2AXtEY89F3Q4KqyUUkoVUGMDODEuOvR4j4kPPd5sGnCcZz0ZuzKK7+S3L+YHu6DFo1NRKqWUiowaHMD59/oexL6Wu8fEc2yHDgDsff/S4td2F4wH7BbwCxd0s7ugRe8DVkopFX41NoDr1soP4JlWD57JO5+n/BdRp+tZALTe9Qtz586BmU9A+iq74PQHAahFNicd05DgakhKKeU2Ovi0ch3Oz7PGBnDBFvA7Vx7P64ER7KcWLTqfwDN5F+ARQ5+vzoAf/o317jA4uCtUfoNpRIzPQ2gxJP09VEq5SGxsLBkZGRrClcQYQ0ZGBrGxsRXar8aOgvZ57XOHEd2bMviY5ND2WJ+XJh36wLqJoW2ezB0EXu2DF3gubyTTrd5Eez1k61zQSikXat68OZs3byY9PT3SVTlqxMbG0rx58wrtU2MDGGDF40NDQewRQjNaXXrecHjurkJlvQd3ArDYtAGEKK+HYBe05q9Syk18Pl+ZUz+qqlejAzjW5w09/vHeU0jbZ49ypk6j0PZ9phYJchCAZbThZyt/lQ2dCloppVSk1OgALqhZ3Tia1Y0LPd8Z1Rhf3j4CBS5zv5d3CnlFPrJg9DqIUkqpsKuxg7DK4r3lD6acPIPrrPvZ7dwn/IvVGYD7z3SmNhPRiTiUUkpFxFHTAi6qXmICV5zUmdO7t6HH062JJ4tMagFw3eC2Tin7/EMbwEoppcLtqG0BB9WvFQ1IKHyL0vuAlVJKRcJRH8Bx0d5Cz39/YEj+EwkGsIawUkqp8DrqAxjgxQu6hx4HlyC06X3ASimlIuOovQZc0Igezfh68Taa1yveDa2DsJRSSkWCKwIYYMxlvYttE10PWCmlVIS4ogu6dNoFrZRSKjJcHsAAuhyhUkqp8CtXAItIqogsFpGFIjLX2faIiGxxti0UkbOqtqpVIDgRh+avUkqpMKvINeCTjTE7i2x7wRjzbGVWKLx0MmillFKR4fouaF0NSSmlVCSUN4ANMF1E5onItQW23ywii0TkvyJSrwrqV7WcUdC6GINSSqlwK28ADzTG9ATOBG4SkROBN4C2QHdgG/BcSTuKyLUiMldE5la7xZ9Fu6CVUkpFRrkC2Bizxfk7DfgU6GuM2WGMCRhjLOAtoG8p+44xxvQ2xvROTk6urHpXGo1gpZRSkVBmAItIbRGpE3wMnA4sEZEmBYqdByypmipWpWAXdKTroZRSym3KMwq6EfCp2N21UcAEY8xUEXlfRLpjXx9OBa6rslpWEecz6TAspZRSYVdmABtj1gHdSth+aZXUKMz0PmCllFKR4PLbkHQuaKWUUpHh7gAWnQtaKaVUZLg7gAG9AqyUUioS3B3AobmgNYKVUkqFl7sDWO8CVkopFSEuD2CdC1oppVRkuDqAxZkLWhNYKaVUuLk6gNGJOJRSSkWIuwMYvQqslFIqMlwewDoXtFJKqchwdwCHuqCVUkqp8HJ3AINORamUUioiXB3AolNRKqWUihBXB3BwCJaOglZKKRVuLg9gdBCWUkqpiHB3AIsuR6iUUioy3B3A6ChopZRSkeHuABYngrUPWimlVJi5OoAlOBFHpCuilFLKdVwdwEoppVSkuDuAxaOjoJVSSkWEuwMYQQCjCayUUirMXB3AzkRYeg1YKaVU2Lk6gAFENH6VUkqFn7sDWOyPrz3QSimlws3dAezQ/FVKKRVu7g5gZypKHYSllFIq3NwdwM5UlEoppVS4uTqABXQxBqWUUhHh6gC2u6B1EJZSSqnwc30AAzobtFJKqbBzdwCjXdBKKaUiI6o8hUQkFdgPBAC/Maa3iNQHJgKtgVTgfGPM7qqpZtWQ0CjoSNdEKaWU21SkBXyyMaa7Maa38/w+4DtjTHvgO+d5DRPsglZKKaXC60i6oM8F3nUevwuMOPLqhJ8OwlJKKRUJ5Q1gA0wXkXkicq2zrZExZpvzeDvQqNJrV9WcLmillFIq3Mp1DRgYaIzZIiINgW9FZEXBF40xRkpZ1cAJ7GsBWrZseUSVrXw6CloppVRklKsFbIzZ4vydBnwK9AV2iEgTAOfvtFL2HWOM6W2M6Z2cnFw5ta4k9l1IOghLKaVU+JUZwCJSW0TqBB8DpwNLgM+B0U6x0cBnVVXJqiM6GaVSSqmIKE8XdCPgU7Gbi1HABGPMVBH5A/hYRK4CNgDnV101q4ho/CqllIqMMgPYGLMO6FbC9gxgSFVUKpx0NSSllFKR4OqZsHQiDqWUUpHi6gDWiTiUUkpFirsDWHQQllJKqchwdQAH1wPWLmillFLh5uoA1uUIlVJKRYq7AxhtASullIoMVwewiEevASullIoIVwewjoJWSikVKS4PYACj6xEqpZQKO3cHsHMbksavUkqpcHN3AOsVYKWUUhHi8gDWUdBKKaUiw90BHJwLWjuhlVJKhZm7A9ihLWCllFLh5voA1qvASimlIsHdARzqglZKKaXCy90BHJyIQxNYKaVUmLk8gNFBWEoppSLC3QGs6wErpZSKEHcHcDB+tQGslFIqzFwewOggLKWUUhHh7gAWeyZoo6OwlFJKhZm7Axi9BqyUUioyXB7ANm0AK6WUCjd3B7BOxKGUUipC3B3AOhGHUkqpCHF5ANujoJVSSqlwc3cAiyCCdkIrpZQKO3cHsEO7oJVSSoWbywNY8GjrVymlVAS4O4BF7wJWSikVGe4OYIfOhKWUUircyh3AIuIVkQUi8qXzfJyIrBeRhc6f7lVXzaoSvA1JA1gppVR4RVWg7G3AciChwLa7jTGTK7dKYRTsgtYAVkopFWblagGLSHPgbGBs1VZHKaWUcofydkG/CNwDWEW2Pykii0TkBRGJqdyqhYPTBV3sYymllFJVq8wAFpFhQJoxZl6Rl+4HOgJ9gPrAvaXsf62IzBWRuenp6Uda38olOhWlUkqpyChPC3gAMFxEUoGPgFNE5ANjzDZjywHeAfqWtLMxZowxprcxpndycnKlVbxyaQIrpZQKrzID2BhzvzGmuTGmNfA3YKYx5hIRaQIgIgKMAJZUaU2rhN4HrJRSKjIqMgq6qPEikoydYguB6yunSmGkg6CVUkpFSIUC2BgzG5jtPD6lCuoTEWJ0EJZSSqnwcvlMWDoRh1JKqchwdwDrXNBKKaUixN0BHKQtYKWUUmHm8gAOTsShAayUUiq83B3AOhGHUkqpCHF3ADtEW8BKKaXCzOUBHByEpQGslFIqvNwdwNoFrZRSKkLcHcAOXQ1JKaVUuLk8gO0WsGgLWCmlVJi5O4CDE3FoACullAozdwewQ+8DVkopFW4uD+BgC1ivASullAovdwewzgWtlFIqQtwdwCHaBa2UUiq8XB7Aeh+wUkqpyHB3AAcn4ohwNZRSSrmPuwPYoXNBK6WUCjeXB7COglZKKRUZ7g5g7YJWSikVIe4O4CBNYKWUUmHm8gAOzgWtCayUUiq83B3AoS5oDWCllFLh5e4ADtIWsFJKqTDTAAaMBrBSSqkwc3cA61zQSimlIsTdARyiLWCllFLh5fIADk7EoQGslFIqvNwdwDoRh1JKqQhxdwCHaAQrpZQKL5cHsHZBK6WUigx3B7COglZKKRUh5Q5gEfGKyAIR+dJ5niIic0RkjYhMFJHoqqtmFdMWsFJKqTCrSAv4NmB5gef/Al4wxrQDdgNXVWbFwiPYAtYAVkopFV7lCmARaQ6cDYx1ngtwCjDZKfIuMKIqKlildBS0UkqpCClvC/hF4B4guHJ9ErDHGON3nm8GmlVy3cJHu6CVUkqFWZkBLCLDgDRjzLzDeQMRuVZE5orI3PT09MM5RBXSLmillFKRUZ4W8ABguIikAh9hdz2/BNQVkSinTHNgS0k7G2PGGGN6G2N6JycnV0KVlVJKqZqvzAA2xtxvjGlujGkN/A2YaYy5GJgFjHSKjQY+q7JaVhXR+4CVUkpFxpHcB3wvcIeIrMG+Jvx25VQpnIKDsDSAlVJKhVdU2UXyGWNmA7Odx+uAvpVfpQjQFrBSSqkw05mwlFJKqQhwdwA7XdCiXdBKKXX02bUevvw7BPxll40AlwewTXuglVLqKLNkCrw3HOb+F9KWRro2JarQNeCjTqgL2jpkMaWUUjVITiZMvqLw82rI5S3g4G1Ika2FUkqpSmTlFX5+MCMy9SiDywNYKaXUUafIdcW5y1dHqCKH5u4ADi7GoBeBlVLq6GEFANjU5yEAZs9ffqjSEePuANa5oJVS6uhj7HE9U1fuZZ+JI6VWVoQrVDKXB3CQBrBSSh01jN0CXpdxkF0mgXPzvoEFH0S4UsW5O4BFB2EppdRRx2kBB/CQmdCOKALw2U3V7n5gdwewQ/NXKaWOIs41YAsPuUkd8rc/nmTfH1xNaAADooOwlFLq6OG0gBEPGztcyWeBE/JfK3h/cIS5O4BFB2EppdRRxwlgg5f4ug25Le9mJvhPCb18MKt6DMpydwDrKGillDr6OF3QeIROTRMAeNB/Jc/l2UvYfzpvY6RqVojLA9imPdBKKXUUKdACblY3znnsIRcfAOvS9kWsagXpXNCAtoCVUuooYoItYLuN+f5VfcnOszgpYw18B8aqHqOh3R3A6HrASil11Am2gMUO4EHtk+3tv0Xb2wOBiFSrKO2ChvwRc0q5jTH518uUOlo4v9MiRSJOvPbL1eR33t0BLNoCVi43fiQ8Vj/StVCqcjmNKgtv4e1OlzTVpAva3QFMcDGGCFdDqUhZMwOAdWn7I1wRpSqRE8DiKdLICraAtQu6+hAdhKVc7q73Zke6CkpVntBEHEVbwM6wJ20BVwM6ClopAF7MvBM++Cv4c/M37t8OSz7RLiJV8zjXeE3Ra8AeO5BNNbkGrKOgQb9glOu1ZAes2cHSxXPp3K6NvXLMzMcBWHEwgY59T4twDZWqgGAL2FOkBayDsJRSEWcFYP0PoaepViMAtn/3OmbKNaHwBZg3dRxGT1JVTeLcByxFIy7UAtYu6MjTLmjlBqk/Q8bawtvm/hfePQeAaYHeXCxPATAk8wvECea/5T7EBk8L6ualsSYtM6xVVuqIBO8DLtoCDj7XFnB1oOsBqxosbTm82hf27zh0uXFnwSs97cfz3sU8lkRgxmOhl+dYnZj2wLmFdnnTfw7H9DuTpMQEYshjT1ZeZddeqapTxn3AOgirGjGawKomWvAB7FwJH10IezZB7oHiZfw5oYebdx/ErP8Bsfx4c/Pnwt1PHLWjvfwxcGxo2xrTlLvO6ABR0UTjJydPJ6tRNYhzyaS6D8JydwCLDsJSNVjDY+2/t8yDF7vAyz3h4K7CZfZvCz38btkO8tLXFDuM33gREXoPGcmKlhcxx+rILPqSEOsDbwwxkkeOv3p8YSlVLqG5oEsehBV6PcLcHcA6EYc6mmRuh+c6wqrp9vN1s2H206GXD+7aiuxO5fNA/9C2O3Kv549aJwIgIrS//HVWnjmRibcNtbdFxdgtYL+2gFUNEpqIo2gLOMp5uXr8Prv8NiRboJr8YyhVIcGz+OGvgDcaZjwK+7fChFEw7EX48vZCxduuHIMvdw+LrRQS6ybx1a4mnHnJHTzZrkGojNcjXNa/dei5REUTjbaAVQ0T7GIuNhGHTkVZfThd0NXlbEipCnG+ZGbkdeXt/f2wOp+X/1qR8P3DOobTM/8HwM++E+hzy7scd84tDOnYkLjoIl9SBYgvhhjy9BqwqlmCLeCiASw6CroasQM4YGkftKqBnBbw/Z8u4/Evl9H/94G82uVjFnZ9kEB0Av/MuzxU9IvGt7DPxPFw3uUMHXQ8taKjuOT4VniKzpVbhMcX57SANYBVDRLsHSplEFZ1CeAyu6BFJBb4AYhxyk82xvxTRMYBg4G9TtHLjTELq6qiVcnSi8CqJnJ6bgLOefSOg4Zn5/p5ls54eJ0oAjzqG8cPga506Xsyc2Lm0ig9i+sHty33W3h8MUSLX7ugVc0SmgmrlGvA1WQQVnmuAecApxhjMkXEB/wkIt84r91tjJlcddWrYk4XdCCgZ/eqBnK+RIIBPKJ7U/63cCsAxzRO5KQODfnAP4knf97P98ck0zAhlopOKOn1xdgtYO2CVjWJFRyEVXIXtFSTy45lBrCx56ALToPjc/4cJU1GJ4C1BaxqIucsPyU5njHXDCG5Tgx1Yn10b1GXv/ZqDkDA6sDQk3NpEB9zWG/hiYrVUdCq5gmthlS0Bew8NzVoEJaIeEVkIZAGfGuMmeO89KSILBKRF0Tk8P6HVwNWNTkbUqpCnOtYzerH0zAhFhHh8RFdQuEL9qjmww1fAKKi7UFYbu+CTl8Fq7+NdC3cLX0lLPwQlv4vf9uqaVgvdmPX6jmFy5Z1H3A1uQZcrgA2xgSMMd2B5kBfEekC3A90BPoA9YF7S9pXRK4VkbkiMjc9Pb2Sql1JQvNwaAtY1UDBCeeLfslUJm8MPgmQm1c9WgyRYt4+FcaPZOOWraUX2rsFdq07jIMb2PBL9Z2QYMknsPTTyL3/wV2wYDy81hf+dz1MGs2q7ftg6wKYcD6ePal8/dHrWAUH0zotYE+xuaDtTl8x1aPRVaFR0MaYPcAsYKgxZpux5QDvAH1L2WeMMaa3MaZ3cnLykde4UhMsjyoAACAASURBVNkJ7NdrwCVb+KF95r/00+r75eBmzll8sS+ZyhRlt579uTmHLmcMbF9SdfUI2r6k+O9iwF94HePKNP58Dn79MJJtjzV9662XSy/7wrHwcg/S95fxsypq1TR450y2zng1f1sg7/A+kz/H/nmU5UBGyVOXFrRlPnz/b5h8JUy6nKVL/qx4fQ7neyNtOexOha/vIfCfkwm83BM+u7FQkQfGf2/XD8gwdbgk8D+2fv1MfmOq1PuAa9hUlCKSLCJ1ncdxwGnAChFp4mwTYAQQhv99VUNHQZcgbYV9tvlaH5h0OaydGekaqaKC9zp6q3A+HSeArbysQ5db9hm8OYBF094t+5gHMjBPt2Tf8lkVq8vamfDmAHZPe8pu/QSN/yvmycbk7t566NCq6KWmAzth9TR2zxkf2jTc+o5NGU5wZe0pcOz8L/RXZ662Ay5jLfzwb/j6bvZMuJrstT+VHI6Z2wH49YepoU1mzGByXuxR4d4581QL0saOLH2//Ttg9beYcWdhPdWC7DnvwJrvipezLHjrZJj1BJuM3XCa/uVH9s89uPjHgvHsfPt89uwvIci3LsS8dSrpb5xFTvaBshcMAfjtDbJeHUBg3HAOvnYS/P4fvNvm483eXazocQd/ha/uwDLC9AaXA9B87v/x9o9OD0RoJqwit9kFB2FVk1HQ5WkBNwFmicgi4A/sa8BfAuNFZDGwGGgAPFF11awizihoy7K0G7qoIl1Ovy9dFaGKqFKVNtlAZfJGAxDIK96q8+fmkJ3nfJHttH8/jvv1VrZ9+lCodWVmPsG2CTeTW3AQ16Y5SPZeFk94sGL/73atB6Deb/+CMSexasNGe/u62YgJEP1SJ7b+96KS992zER6rx6pZH9ghvWXeod8rfSVm4iUANJMMAH4JHEsfzypy3j4La+44+FcrvprgtFp35Lc/mvk3wr/b2CtQzXwCfh9D3VWTiH3/bH58/Xqycot8+TsnDQkcJCPT/jnLjqXEZG7mlS9+sRfaWP4lLPr40CcRuzcggRwabpvF978X+HzjhrHvM+cK4YcXwPiRSPoKPCZA7De34/9gJD+s2F7k55Uaenhd7t8B8GRuhzEnsfPFgew7mA2f3UiDTdOo+1xT5s2aYp+EfPeY3Q0/ZjCy5Q+S034h5umm8Nwxdrfx9iXwSCJLf51q/3vmHoT1P9pd8FPvI27nErwH06jl303ACOusxiV+1H8EXrPrJIb9x13O7oROAKze7pwUlXZ5xhMM4OpxSaXMADbGLDLG9DDGHGeM6WKMeczZfooxpquz7RJjTA1cMDT/7OiQc3Ec2Anvnwf7th2i0FHmQOHr9dN/XxyhiqhSOa0ur7fqu6CNv0gAb5lP1P815L5nXsSyDNaOZaGXmvz5CnNeupjcl3ohP/ybJqveZ+zXP9ndkZnpsG+LfUxg8+4sWPYZB946i3Xrii8UUUiRhSZ+n/R8sRZl063fMvX9f2N+fZ2cp1L4Zcxt7M/Og02/26/PvpN9k26At05h9ZsXkfbFo8Un4gn44bW+yMZfC22e0OAWMmJa0O7gQjxf3gZAgxXvs3XJj/CfE0Plum2bFHr8UN4V/Fz71NDzQRmTmPD6o+QFL3ulLYdv7gagkexm+28f24Hr6P7HvfZCGxMvhinX8Ok7/yr957Muv0fhuK/PZfvebLtLOvVHEha8ybw//yzUc7DbxAMQhcWcP4oMYnL+PUfm/IN/3XQJOb5E+nmW2585kEb2fwrf0Nbr+ytYM+lh+PE5eLlHidX7ZdyDWCu+BqDJ1Kvg5e5kPtUe3h0G75xZrPw8cwzr2lxMlokObZsmJxQr1ygxjnp9zgcgLsr5t3RO7IqdnHqq121ILp8JyyaQ/x+iJH9+CGtn4v/h+YofPJBXvmsy1YzxF+5ybC7pOmNYdWMC+PHgrcr/xV47gNttmswjjz/E1CX2SWjmtMcBODf7M1K/fw/Psk85aGIYFfcWAP0OzCJ695rQl2fdBW+QNXc8PNuOtJ/fAyBesqg/ti98fBm1t/zM2x9+dMiqmN2pAGwxSfwQ6MpF+8eR92TzYuWGrn0CmXY/MTm7OGHrOGZ9/Aq53/2f857ZJKy0py5ov/0rGs57ng/efQMrfQ1Z4y/mj6kfYFJ/KvH9ffVbUOe0/LGm6SaRfp4VRH11m/M8AYAmexeQZuryqudiug2/lQF3fMSeuJZM9J8EwEW732DJ2OuYt3Ae5s2BoeMd51lP559uZstL+YF9orfwie/AjW+w+pNHOfBkChM//iB/4JExBJZMCZWrL5ksnTOdrHdHhbb1+vTEQse6M+E5FpxjT+kQnzqdwK5UMl89kU1vnMeuPyYSwEOzjv3o2jyRvLhkjncCGKDh3kX8y38hY0/6jcy2ZwPQbvlrxX5mI80zoceXZ7/H4gW/heoHMMvftfgP2vGH1YGkk29mzdWrSO15P683epTj7/6cA3XaAJBrvDwUfS8ntk/On2Aj+F0bXA+46MmproZUjThd0II5dLg4/2hTfltZ4bewXu/PjhcHk5lTQgjnZR/eqMkwsHKzWG81Cj1vJjvZtOtgBGukirECWHjwFp3tpzJF2QF6nXzKI4FXmPDrGvDnErP5FwD6eVaQO38CYLf2XrzuHDLrpACwwWrIg8d+y7Z2f2OUNY19M+wv44Z7FwHQ3bOO2gfzW3ujcj4hbez5bN1epDvUaa3kpq9hvtWOx9t+RPfbJ+MRg88q+dr0b1YnxrSwW4vD1z1K9J61hV7/MtCPGfRlk5XM8NQnWfLNm8St/pKoX15g1/dvkEUMT0ddzze1zw3tk1Qviehel/DryHnMvmAF3ovtE4aGWWv5JtCHbQPtkG+Zt57frE50u/BRRvVrA14fCXcv4syHJpM5bAxxkkuPbR9zzKdnIyUsCtDM2J9/GSmFtr/a6DGSZS/tFz9P7bxddFzyHCvXb7B7Br6+C+/67/nYP5j17a8k2/g4+ZfRxG36vsSfD0DLdl3o0eN4Muoex5X+iSyb9DjxO/+kxY6Z1F/3OTMCPRnQuZVdOL5hoX3XWE2JH3IXV5/UifgB1xY79k0tP2P9TVt4/a7R5N2Z/7Pvtjf/evN8qx0Hh4/BGvYSAF8EjgfsYAX4w+pI95b16NqiHq2H38eNN9xOYi0f0qAdAPfHPsQTDzxAvdrRoZZtIBjAocszJU9FWZOuAbuC/1AB7AySqCeZdnfWoVgWzHzSPlv/6QU8GatptH8Jb32/uli5wFunwss9+Hp2yWfckWTlZpNNDKPNo2w39ahNNhs0gKsXEyBQ1S1gX61CT70bfmbB2BvxWdl84htGLcmh4/7fmBIYyF+vvJtmdeMgvgkAa0wzTu/ciCYjniAvqjaNcjaEjrPXFD4u2IHccPM0ar3Rk3HfL4dln7Fz3MXkPt2awCP1idnyG79ax3LN4HYkJDUmY9g7/CFduTR+DJbHB8DNtZ8jPaYFnza7i4vOyw/PlVZzlpn8QMv7y3859ZFvaf6356gnmRy3zm659/CsIWnjVD7xD+T4UXdy5jkXhPZpnBgLIvTv0o6TOjWhfvv+bO59P18mXUFa/4fp3K5NqOxSqzWdmiSEnns8QkKsj/juIwh4YwGoI1kstOxpQTdayWxtkt/yBVgXY6/3vM5qzJThS7nu8isKvd7Nsw7ePYe8V4+HP8YC8F7sRbRo1ZpYycODHULfBnoV+1k/nPIh957ZCTwekobeT4zk0XFb4XEf4wJncF6PZgD4Eu1rsb9Znfj6jNmkn/85153ofN42J3Gw/52h/e5q+wWvXjGYlOR4GtaJxVenARl97ypWh+2mPs3q1sLTdSTrW41i8/GPsq/x8bxX72ZS+/yTO66/DpHic5XHNu1CromifocB+RuDLWC/8/0cmgu6yADFajYIy93LEUbFAfa1l9JawJZlyN25kVjgNO88Vn/7MnXOubNwmd/HsqdhP+q37moPRvnhGQ5+/zK1JTtU5mDqPKBT/k4bfsabZncv9Zl1Id/Wmc5pvTpRXVh5WWQTzalDRxCY8wXeXZkc0NmQqhfLwsJDVFW2gFvlf8kZhHeingKngbqq/dVkHLDISZ3DjAaX8WLr+gDExNr/r5aZVoxomgjxtYi+9lsWTXmaersX0SJ3LZMCg7ks5geiA4VH0K63GpHi2cHyRXMg4zYaFHhto5XMwsajuLFlPQCSev+FhB4jeMsyePb34acfZ3HHCReQnHw1wSule/rfz/Qd8fQ4YzTH1M6CZ9vznv80Rna2A0XaFQ69oBmNr+KdY5LBfwo7WpzJpA3x9GtRt3AhEZoPu49QJ3jaCgD2mVq0P+eukidAiYrBe8cydn7zJHkrp7Oi/3/oPqAjidkBEmvXYveYYdRLm8MuE09Gs1Ng3VcE8NK9RV18cfGhw7wTGMoV3ql08mwE57x4udWCZ68+i6i0/NHUt8Y8zkv33AiPJ4W2vej/C49ceibe4Ajhpt0B8BHgQ//JnNCtI+mr53LpXy7B55zdRbcZCMunsM5qzIkdO9C8XuETqFoN808+Upo3LRacSWc9zMENs/l1TyLdY7aRtG8ZO0w9OtWLg5japFwxlhsAmMbVJf6L5PMMvI0dzU7ntrYFTiyCLeDgaPTQHQJFAtwJag8WlmXKXIykqrk7gJv1Yn9cMy6zpuMPPGxvswL2/WXNe4MIF4+dw983L6Ob+IiRPNrPe4xPorrw1zPPIPDDc+z8fRKNMpdTH9hyzKU0W/U+QCh8/5E3msd87/Lg1pv44t8z6dUigcW0ZdD+bwiYOMY1uINbMp6k3+cn82fUNxz79Xl82PheLr38evuXeM9GyEyz6xNGJi+LbBNNfGwUdeNrsWPXnkNfJ1fhZywsI3hKaCVUmph4uG0ROw9k0+CPF+HPCaGXUlq3Janvh6Tty+KFWtFER9lf1lFZaQDMCPTklvr2F3VUo44cd8M4+7acmU+w3dTHd+cS9lpxxFr7iXm+PQDvtHiSx7ZcTZf0b0L9c0utViw88W06tm/LC40TCn25+7wefF6gfhsGnpsfAkF1z7iP80PP6hC4eT7n1WpGrWjnqy+6NvxzD7vHX0nWpoU0zVnHq/5zef3aM+z38cXR6KqPuMmYEltjhSR3wDrnFXzHnMPIOvVKL1c7iQYjnwdj+JtzzEQnqxMbtoS0OUwJDOK0vj1hHawyzRiaVLvQISYmXsnlffsgMx8PbZuSOJoHGtWBg/mXjnzJ7RFvFLnN+rFuSxrZF03htnatCt+eU6cJlkThMX5m+E7iwlG306pIlaX3laRlgeR2tns5impwDGAPnOrVquTPXuuG7xgCWJ9cC4uXkUM0TRJjS/85lSauLi2O7V94W+gasNMCLu0eeedk1YtFwBg8aABHjjeK1SmX0mfZ02TOfBD6XsKBrx6i9ha7S3hSp5d4YvPTtPVsY7x/CMsbnc0/d97N4N+u5qs6n3L2zMdoVOBwwfAFeMl/Hh3q5NDq5JvZK51JnHkP5xz4BFZAU6fMP+R6Lr/gBg588BEJ+9bS7dOTAEhZ9wHb9l5O07pxmJd7IJafScOWMKp3i/D8XACTl00OPuJ8UeCJwoulAVzdOF3QUUXP8itbvVY0qAck/ANr2Wd48g6Q6UtihNM92TCh8BeynPMSO356n7eGFr82SL8b2JWRzvButyG16pMIQBxc/Akr163jgZNH4H/mVi7157fillmtOP/kXqHW2JHwNmhLnaIbRah3yTvUm/Yg/PoqB01sfkCHipTjZyyCp9dllBBPpZYvylPL7kXY12EUrTr2JPvct+jccFCotWqdcBsbF87klUtPQOqfyL7U+SSs+4pnY27iwTvt0dQ0aB86Xm4t+xsq+uppdCzlPRHBc9sC1vz8CXd2v7zUujY88SouLO2ztOgLV39Hr8bHhcYNlMZz2iPs3boCX4NhxPoqaQR/KIALt4CD20OcLmgPFgHLUFlvf7jcHcDAhlZ/peHSsTRfOBYWjqXgeWb7pS/T1mOP+lxmWjF06HAy9yfR4PPRnD1jSKHjWAieAmtU/Nz8Wm67Pjhk/hgYcCVr/5hKnT9epmHG77zvP5ULb3qQNg3rwN/nsWvMcKK2ziVBDuKTAEvXbiBn9dukOIM0fpn6IT2TRtE2pfDAjDJlrIWVX0P/m0v+zwf2desxg+HY4ZiVU9nZaADxedlkk0BctBeP14ePAHkBHQVdrTiDsKq0BVxQQhM8t86HnP3Ex9Wj1G+vZr1odEHx644AxMRT/7xnqF90e/tT6eDkRl5Se9hhz7r0a+BYTrr9nUoJ3zJ1vwjr97c4a+RNVf9epTnlITj2XO5obXf9x/Y4n9YFXvac/hitT38s9DzhsgmYLQu4s0m3/EIJTck76wVm/zqHa4LXacv6HanbknZn//3I6l7eXrqEpiTe8gNXHdm7FVZ0FHRoKsqSB2F5sQ497idMXB/AnpjaPJZ3KWOiXwhtS/ckk2yl092TP3pvjdWMHi3rER99LvsWnsr8bblsaHsRpww+ldicdBLq1GbVj5NptmUqUTuXc/fQjoXfyOuj7fHnQLtOpE+4lsQeD+YP0hCh/lWf4DdC4Os7OH7Be/BFv0K7v+B/kq/+O4Pov/+PFk63njmQQZa3NrVinW6c1J9J++Etcoe9RvP6zqnEhAsgYzXfr97N4AEnQEnXvLJ2w/ZFsH0RAuRsTsUXF0s2SdT3ecEbhZeATtlZ3QRbwOG8jlWnsf2nCvkadoAdf/Kn1Ybk6z4luUGDsneqDI0643k4jS7hebeSxSZA6wFllytAmhW/79bX90pO63tlZdWq+gsGsBUchFXKJDVOuSinBRxprg9gr0dYbOVfO+qQPY6ptw5kzTfP0H/TGABe9w/ndzoSH2P/uBKu/ISTCh3Fnqqt64g7wbodjKFPadMDNmhH8q0zGV50e1S0/Y/ReQQseK/EXdvKVmbOW8JZbWPInvkvWmz+ilrAl77T6dGuBc2Wv01DYPh/hvH5/SMBMAfSEWDw+udg/XMsuWYjXZolFj5wZuFp4jJNHPF5WeSYaOJ8dgs4ioB2QVczxrIDONIDSSrd0KfZG9+axv1uo1Hd+LLLK+W0bK0C9wFbRvAW7Tkp0gUdaa4P4CiPsI36/K/RzaQm9CF2TS1aN2lAyqWPwgeLoVEXRg16ggvL2wV2pBPjtxuCNeo9MtK2ELNjIWlWPI3zNsPONXTcv5aOP58GPxfeZVjedMi/R56offn3VgbEV+gfecbyHWUGcB05iNfKJRsfcdFexBvlBHDkf2FVPmMs+zakcHVBh0vtJBLPeJDEsksqZQte6y0wCtq+Ra/oKOiCXdCFGxQ5/gAxsx61Zz4c8XpV1xjQAHYmMRBu33AC3VvUpVMTjz3gIroWXGkPBAn3Gk6ezueS3Nl+HLqTcMVX8FEp89wW0VLSMM6oTavILFxWSa3YTHvU6o+mO509G6hjDuIzAbKJdgLYh1d0EFZ1YwIBDFL1g7CUqu5CAZx/H7BBil/6FsEgeCS/BTxj4Rqu/mgFIKxoN5dYCd/Mha4P4IJfXuvSMxnevekhSkdQx7PhwR0QyOXgDy+zO7kPjdv3Im/1TFjyCbFr80eNvhj9Oo8+W5+mLdpwTW7hlUQyMtKxl3EG9u9g+wfXkO5tSFfgqw7/x6Am38P39l2U2eR3QfvwV4tBCyqfsQIETBgHYSlVXTldywVHQZfWO2TEixeL9ekH+P3PJZw781RSY+HO3Os5uHsHsc07hK3aGsAFuij2ZfupX+vQQ+gjyhcLvlhqnf4QwdvgvT3Oh+6j7EnXcw+Q9+mN+NZM5Z8HngB7XgBmeAZwqmX3Wx/IsLunDyydTu1Jo2gMNAayTDT169WHmPzZe3KMzwngSr4NaeKlkJcFl0yunOO5VPAacFgHYSlVHYXW+c2/D9hCindBAx7j58yo+QwZ+xv3RX0YSsGnosdyIKsO1E4qtk9Vcf1UlEX/gRLifBGqyREQscO5dhK+SybCHSvIa5k/yfuPTS6Hq74FwJ++jvVTHqX2pPxJ2nPw8b/487mwXyt7FGZoezSxPg9SmYOwMtNg+eew5lv2ZpUxrac6JBO8DUkDWLldqAva/o4KDVAspXeoLZt43vcG10d9yXZjTxziFaGetZv93rol7lMVXB/ARe8vrFudW8DlldAE3+jP8NdujGWEJinHQkN7mstXPf8mZZG9qtOKDjew4dQxRD+0hQvvfs2+vSk2f+hLwBtrXw/3ROEjgL8yBmE9mz9JwDNTVxz58dzM8msLWCkoEMD29VtjLEwpLeCgv3jtCZca9joXLhiP19gNgm9TwzdPtOu7oIv+AyXWxBZwSbxRRJ3yAHtXzGb0iZ0gOn909pyo3rS44h06NmtZfL+Y/HmCug8eETqWVwLkHmkLuMiAsJa7foYJT8DfPgxNEafKzxhLW8BKQfEAtgIlj4Iuadc+V0JSu/wNtZIIWKZc+x4p13/rFW09HDUBDNBrNIkXv0NcMHz7Xkdug2Ppc/+3NC0pfAEadYEW/eDqmYwYMsje5rFvQzriFvC+zYWeXrL1SVg1le9+/OHIjutSxrnOpS1g5XqhiTiCAWyVPkvcQ2n2zIAAQ/4JTbrZc4K3tGcu/MvAbmEJX9AWcLF/oKMqgIs66xmijTn0tHTxDeGq6YW3eaKIwiLPf4RdM86C6kH7vfWoHdjHrOn/4+RBg7UlV1HBs3wdBa3cLrjOb4EWsFXaUp1RMTDgdti3BXqOzt9+8SRYOB5SBoWhwjbXt4CL3lpzVAcwlD0nbEmctVYDgSO8Py6j8KLolrN2Z1vZyta9JS+srkqX/yWjAaxcLtgF7azzm5WTi4VQr7QxPfHJMGpc4RHPMfHQ7zo7oMPE9QGclVu4VVe31lEewIcjOMQ/cGSjls2OpYWeN7W2AhBDLgdzq8cC2TWKKf91LqWOak4AizMTVvburWSYBDo2TjjUXhHn+gBu1zB/rtmOjetU3vJYRxNvsAVcgQA2Ts/Cnk2wz15RKmfznyUWjZU8DeDDYKxSpttTym2KdEFH7U1lo2lE+0bVey5x118DTq4TQ+rTZ7Nqx35aJdUqewc3cs4ug13GZQr4CbzaB2t/Gj5/Jmu9bci+bCrHpC9lkv9EzmglJGz5PlTcbgGHb/q3o4YVKPNWC6VcITgHv+XHBPzUydrK3rhe1b5B5foWcNAxjeoQE1W9/7EiJhjA5WkBWwFy3x+Jd/c6fP5MANoG1rF28kP4Aln8Gn8a8Rf+Fyu+CVle+5anWPKKXQpQ5WDsqSg1gJXrOd9RXrEI7N2Cjzy8SW3K2CnyNIBV2YIDHEobhLVnIz++fS+P/28h/i0LiU6dFXppqdUKgOH7P2ah1YaThv4FT3wDPHcuJ+6hTWQ17k0suRyoKQHsz4WdqyNdC6BAF7SOglZuFwxgLDauXAhAYvNOkaxRubi+C1qVg/PLHSilCzrw+1gGbXqTZes3sWvxXBoC1+X+nXtvuoH6cbH4l73LurnTyDnjFYZ3am7v5ISG+OKIlb1kVdcu6M1z2R2IIbFFF/s2qd/HwPQHCeDhawbSvtcppDc5hUG9u4W/bsYZBa2rISm3c76jogjw++8/0Qbo1eeEyNapHDSAVdmcQVimQAv43V9SiYv2cn7vFqRvXkdj4LqoryAA+00cN9/4d9oE1x0eeCvHDLy1xEN7ouOIoZoNwsrLZv/Y4XxZ7zIuXHET9YD720zmqctOw9q5Gg/2mfY5/ADzfsBn/YfJMoORvZqHt55WgABeorQFrNyuQAvYm76C/bH1SWpYTVe2K0C7oFXZiqy1mbrzAI99voh7Ji9i1/6DeDcUnsnqz3On0bV5+ZZT90bHERuu25CMyV+wO8iyQiO2Mz+6hkmv3MeuDYups2MOF664KVRs/wZ7BHf23jT8xoNf8u8vbOvZxiez5mCMIW1/NhP/2Mieg7ls2nWQrXuq8P7m0hYdV8ptnEFYLSWNs71zyG56fIQrVD4awKpsoUFYdgt4x+z/sDb2UpqQwdqPHyRZ9rKtXm8A8loMYGDP8nfHenyxxMoRjILOyyLz26fZlLarzKI5k6+Fx+oz5qGLmLUyDYCsrx9gx6NteXL8NOJXfMyojDf4cMI7xfatnb2d7Fw/uzYs4UerK+tPfhWApR577dCU3T/z7KTvyH2+G3U+v4ovpnwAL/fgyn+NY/3OA2Rk5jDj60k8PmE629PT2fHGMF786OtSKrqfg7+/T2Z2GYPejI6CVgoIfUed751NnOSSfN5TEa5Q+WgXtCpb8BpwXi4A/ZY8CkAHzyYabPiKHE80Ta76EKwAvgrOIiO+OOLK6IJevHkv7RvFl3xLwW+vE//zUzwzeyuPPfly6W+Ul03M0o8BuDbqK67/9WaO2zebpLlvEAc8uPr8UNGbrPHFdk+R7cx4eiTDrI3MNu3p3WUwZnl32p39Mv4PL+D/DrwNy94GoLl3O6tWbaGFZzt3RU3k24UD6Pf7rZyau4BTgcfX3czD/h/pvPUAv6ztywltGxR+s2//Qa25/+Waabt46+HbSv9MFZhwXqmjmvMdVUey7Dmd67WObH3KSVvAqmzOL3fa3gNc9c6c0OaenlWkeHYwvdlN9hzSCU2gVv2KHTsqjhgpfhvSjn3ZXDXuD9Knv0DWmNO44YN5ode2rFnEDyvT2LY3i9yd6wGII5f0nRn8uGoHAAHLEHCmGf15dRqzv/mo0PGzVs0m6atrDlm1rFpNOdD7Jvyx9bk+6guGWfbo7gtu+Cd16jdGrvuemObd8NZvFdpnd60UAI7xbAGgV9Q6cr9/gW65C0Jl7sobA8Bp3vk8MXYiGzMOFnpfs387ALFZaRhTeKrUnLnvM/HFO1mxfZ/OhKVUkKdAW/KMJyJXjwrSFrAqmzd/hOHClWsh1t58XePVsBO69zvp8I/tiyWGXBZv2Ys/YBHlzJ6++ovniF6VQ3LqSyR74KaVq1iypQNxqd/R9tsriDEJa34KHwAACrlJREFUNJB97DbxRAu0ky0kv9qG8f6/UG/0Pzj4xb0867+Au4/ZRr8FDxMlFvtNHEsGvkr/n6/i3eh/haqQ3vkqGqydgtXrSjxJrZHFk7BankDc4HvtZRJXfQbZu8huO5TYv76Br8hJhiQ2h03gb9yDepdMgmftpc0W+nrQPW8BN3unhMrujWtBYtam0POx0c9yxyc9GXZcUzZkHKBXq3qc7IkjBmgmO9m6N5tmdeNC5WO+vJkLgMu/uYDXneUI9TYk5XpSoC3ZtGfk6lFBGsCqbM7ZZetEL+28O+GAvTlmpz23c4sOvQ//2FFx+PCzfOse/vrGL3RrUZderepx7upnGFhgHvWR3h955bXV/Cf6RQAayD4A6ok92ceoKHsg2O1RU3hmnI97fNP4mGmwEPYRR6BhN7JanMjxffrCz/YxlzY7n2Ou/A/JXg/wPKEO7p6XFe4aGjUOsvcS2/7Ukj/Dmc9AyolE9bys0GIXbc5/Cv54Ceq1sldeWf4FiYOug+kPhco0lV302DCOk7bM4LtAD178aQhNk7ZzHNBatvPJvM3cOqQ9AGk/jaOhs19tH6BTUSplK3gSWoNOSMsMYBGJBX4AYpzyk40x/xSRFOAjIAmYB1xqjMmtysqqCHFWQ3o+/n3Yuarwa8md7FVEDpdzzfjcjvF8umIvf27ey+RfV3JubOFi9/ryu5DX1e5OmwP2zfZb215Ak5hsZNlnodfv8U0stO/qlEvpOfoZ6onkj4LufzOdT3+ifP9ZW/Q59Ou1k6DX/7d397FV3XUcx9+f0kIRWLtBwbryUAIOquGxY9Q9KCwIEjcTRQObgoak0RDdoskcI86HmAUzMzaVsKG4YaJDnW4gCSBjJOrIiuVx0IoDeVgRVphQKBtldF//OL/Sm6ZAW1pOz9n3lZz0nN853P4+3NN+7/39zj3N+LNmX1sPVS9xw4jJMLIsamu8CA1noj8YXlMJxXdBzz7Yxu/z3foo27zsjXwup4IjZ/pDFnwyey/T/7afMUV5lBTewMCXm+eDL9TVhs8B+0VYziVVW94BNwBTzaxeUg7wD0nrgG8DS8xslaSngfnAsi7sq4tL0/xKZvGd9xdAUDDq2h473N7yiZNf58sf+wI3D/sofSt/AXXNh5y/8xFyt/wUGi9guXkML/8dbP8NjL6Hjwwsgeo1ULWaupGfJ+/4a3D2v9T0/wRFb2+hfsBYJs5d3Fxos3rAo6ei7a56pTy0LFoy9chunh//0spLzdq2EuqPc3DiIooH5pG/7iH66SwNyqXQTnB346uUP9vAYNWyKeP6thNHD3C2VwPvWxbZXoCdiwwsibsH7XLVAmzRVSD1YTMnLAZMBe4L7SuBH+AFOJ0Gjoa+g+B8Hcx8PHoXV3xX5zz2oOgHRvXHmVi/FDL/ZPC0H8HpI+RO+irc+hWoq0GDJ0X7pixsPm70PTD9MfLGzIZTB2H9Qopmr4SKZ+h76/zmG7U3yepG1x5OmAtHtlB8+xej/1cgKzuHXvetgg2LWFL7c5Zk/JRWDC3ntsPLebL3CgY1niQnJ4eCftfv75c61219c3t0MWiCqOVVlq0eJPUgGmYeASwFHgdeM7MRYf9gYJ2ZffxKj1NaWmqVlZXX3GkXg3f+BxfqIX9I5z/2hXOwegGcPwNTHoFju6C2CmYsvnQXrlS7cA569oluCLL5MSi+M3qBU1cDW38J507A6SNw6O/wrZ2w6n6ojebfG6cvpkfZN2IO4Jy7HEnbzKzVC2XaVIAzHigfeBH4HvBcWwqwpHKgHGDIkCETDx8+3P4Ezjl4713I6Q0XG+DdU9Cz77XNvzvnutyVCnC7xuLM7DSwGSgD8iU1DY4VAUcv82+Wm1mpmZUWFBS059s55zLlhI8jZfeCfh/24utcwl21AEsqCO98kdQbmAZUExXiWeGwecDq1h/BOeeccy215SroQmBlmAfOAv5gZmslVQGrJP0Y2AGs6MJ+Ouecc6nSlqugdwPjW2n/DzCpKzrlnHPOpV03+jyGc84598HhBdg555yLgRdg55xzLgZegJ1zzrkYeAF2zjnnYuAF2DnnnIuBF2DnnHMuBu26F/Q1fzPpBNCZN4MeAJzsxMfrbjxfcqU5G3i+JEtzNuh++YaaWav3Yb6uBbizSaq83E2u08DzJVeas4HnS7I0Z4Nk5fMhaOeccy4GXoCdc865GCS9AC+PuwNdzPMlV5qzgedLsjRngwTlS/QcsHPOOZdUSX8H7JxzziVSYguwpBmS9knaL+nhuPvTEZJ+LalW0p6MtpskbZT0Rvh6Y2iXpJ+FvLslTYiv51cnabCkzZKqJO2V9EBoT0u+XElbJe0K+X4Y2oslVYQcv5fUM7T3Ctv7w/5hcfa/LST1kLRD0tqwnaZshyS9LmmnpMrQlopzE0BSvqQXJP1LUrWksjTkk3RLeM6aljOSHkxqtkQWYEk9gKXAZ4ASYI6kknh71SHPATNatD0MbDKzkcCmsA1R1pFhKQeWXac+dtRF4DtmVgJMBhaE5ygt+RqAqWY2FhgHzJA0GfgJsMTMRgCngPnh+PnAqdC+JBzX3T0AVGdspykbwBQzG5fxkZW0nJsATwHrzWwUMJboeUx8PjPbF56zccBE4B3gRZKazcwStwBlwIaM7YXAwrj71cEsw4A9Gdv7gMKwXgjsC+vPAHNaOy4JC7AamJbGfMCHgO3AbUQ3AMgO7ZfOU2ADUBbWs8NxirvvV8hURPSLbCqwFlBasoV+HgIGtGhLxbkJ5AEHWz4HacmX0c9PA68mOVsi3wEDNwNvZmzXhLY0GGRmx8L6cWBQWE9s5jAkOR6oIEX5whDtTqAW2AgcAE6b2cVwSGaGS/nC/jqg//Xtcbs8CTwEvB+2+5OebAAG/FXSNknloS0t52YxcAJ4Nkwh/EpSH9KTr8ls4PmwnshsSS3AHwgWvWRL9GXqkvoCfwIeNLMzmfuSns/MGi0aCisCJgGjYu5Sp5D0WaDWzLbF3ZcudIeZTSAaolwg6a7MnQk/N7OBCcAyMxsPnKN5SBZIfD7C9Qf3An9suS9J2ZJagI8CgzO2i0JbGrwlqRAgfK0N7YnLLCmHqPj+1sz+HJpTk6+JmZ0GNhMNy+ZLyg67MjNcyhf25wFvX+euttXtwL2SDgGriIahnyId2QAws6Phay3RHOIk0nNu1gA1ZlYRtl8gKshpyQfRC6ftZvZW2E5ktqQW4H8CI8NVmT2JhiLWxNynzrIGmBfW5xHNnTa1zw1X9U0G6jKGXLodSQJWANVm9kTGrrTkK5CUH9Z7E81vVxMV4lnhsJb5mnLPAl4Jr9S7HTNbaGZFZjaM6GfrFTO7nxRkA5DUR1K/pnWiucQ9pOTcNLPjwJuSbglNdwNVpCRfMIfm4WdIara4J6E7ugAzgX8Tzbstirs/HczwPHAMeI/oVet8ormzTcAbwMvATeFYEV35fQB4HSiNu/9XyXYH0TDQbmBnWGamKN8YYEfItwd4NLQPB7YC+4mGx3qF9tywvT/sHx53hjbm/BSwNk3ZQo5dYdnb9PsjLedm6PM4oDKcny8BN6YlH9CHaIQlL6Mtkdn8TljOOedcDJI6BO2cc84lmhdg55xzLgZegJ1zzrkYeAF2zjnnYuAF2DnnnIuBF2DnnHMuBl6AnXPOuRh4AXbOOedi8H8F8ui2NiTI5wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2wmDgVRwbta"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}